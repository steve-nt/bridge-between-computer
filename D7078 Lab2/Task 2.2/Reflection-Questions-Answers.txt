===========================================================================
TASK 2.2 REFLECTION & ANALYSIS QUESTIONS
===========================================================================

Based on the lab exercises you just completed, answer the following questions:

===========================================================================
Question 1: What are the advantages of using the AWS SDK for Java instead 
            of making direct HTTP calls to S3?
===========================================================================

Think about:
- Code simplicity and readability
- Error handling and exception management
- Automatic request signing and authentication
- Built-in retry logic and resilience
- Type safety and IDE support

Your Answer:

The AWS SDK for Java provides several significant advantages over making 
direct HTTP calls to S3:

1. ABSTRACTION & SIMPLICITY
   Using the SDK, we write:
   ```
   S3Client s3Client = S3Client.builder().region(Region.EU_NORTH_1).build();
   s3Client.putObject(putObjectRequest, RequestBody.fromFile(file));
   ```
   
   Instead of manually crafting HTTP requests with proper headers, signatures,
   and authentication. Direct HTTP would require:
   - Constructing proper HTTP headers
   - Implementing AWS Signature Version 4 signing
   - Managing multipart uploads manually
   - Handling encoding of special characters in object keys

2. AUTHENTICATION & SECURITY
   The SDK automatically:
   - Signs every request with AWS credentials
   - Manages temporary credentials from IAM roles
   - Handles credential rotation
   - Uses SSL/TLS encryption
   
   Manual HTTP calls would expose authentication logic and risk implementation
   errors that could compromise security.

3. ERROR HANDLING
   The SDK provides specific exception types:
   - S3Exception for S3-specific errors
   - Structured error information (error codes, messages)
   - Automatic handling of 404, 403, 503 errors
   
   Direct HTTP requires manual parsing of status codes and error responses,
   making code fragile and error-prone.

4. AUTOMATIC RETRY LOGIC
   The SDK automatically retries transient failures:
   - Network timeouts
   - 503 Service Unavailable
   - Rate limiting responses
   - Exponential backoff implementation
   
   Without the SDK, you'd implement retry logic manually, risking bugs and
   performance issues.

5. MULTIPART UPLOAD SUPPORT
   The SDK handles large file uploads efficiently:
   - Automatic splitting into parts
   - Parallel part uploads
   - Checksum calculation
   - Resume capability
   
   Manual implementation would be complex and error-prone.

6. TYPE SAFETY & IDE SUPPORT
   Java's strong typing provides:
   - Compile-time error detection
   - IDE autocomplete and documentation
   - Request validation before sending
   - Type-safe response handling
   
   Direct HTTP would use strings and Map objects, losing compile-time safety.

7. PERFORMANCE OPTIMIZATIONS
   The SDK includes:
   - Connection pooling
   - HTTP/2 support
   - Request pipelining
   - Optimized serialization
   
   These optimizations are difficult to achieve with raw HTTP calls.

8. CROSS-PLATFORM CONSISTENCY
   The SDK provides consistent behavior across:
   - Different OS platforms
   - Different Java versions
   - Different network conditions
   - Different AWS services (uses same SDK patterns)

CONCLUSION:
Using the AWS SDK for Java dramatically improves code quality, security,
reliability, and maintainability. The time investment in learning the SDK
is quickly repaid through reduced bugs and faster development.

===========================================================================
Question 2: Why is the Builder Pattern beneficial for creating service 
            clients? Provide examples from our code.
===========================================================================

Think about:
- Flexibility in configuration
- Readability of code
- Optional vs required parameters
- Method chaining
- Immutability of created objects

Your Answer:

The Builder Pattern is essential for creating S3Client because it provides:

1. FLEXIBILITY WITH OPTIONAL PARAMETERS
   The S3Client has many optional configurations:
   - region (required)
   - credentialsProvider (optional)
   - httpClient (optional)
   - endpointOverride (optional)
   - retryPolicy (optional)
   - metrics (optional)
   
   Using a traditional constructor would require many overloaded versions:
   ```
   // Would need all these constructors:
   S3Client(Region)
   S3Client(Region, CredentialsProvider)
   S3Client(Region, CredentialsProvider, HttpClient)
   S3Client(Region, CredentialsProvider, HttpClient, URI)
   // ... etc
   ```
   
   With the Builder, we configure only what we need:
   ```
   // Only region
   S3Client s3Client = S3Client.builder()
       .region(Region.EU_NORTH_1)
       .build();
   
   // With custom credentials
   S3Client s3Client = S3Client.builder()
       .region(Region.EU_NORTH_1)
       .credentialsProvider(customProvider)
       .build();
   ```

2. READABLE & SELF-DOCUMENTING CODE
   Each builder method clearly states what it configures:
   ```
   S3Client s3Client = S3Client.builder()
       .region(Region.EU_NORTH_1)              // Clear: sets region
       .credentialsProvider(provider)          // Clear: sets credentials
       .httpClient(httpClient)                 // Clear: sets HTTP client
       .overrideConfiguration(config)          // Clear: sets overrides
       .build();                               // Clear: builds the object
   ```
   
   Compare to a constructor:
   ```
   S3Client s3Client = new S3Client(
       Region.EU_NORTH_1, 
       provider, 
       httpClient, 
       config
   );  // What is each parameter?
   ```

3. METHOD CHAINING (FLUENT API)
   The Builder returns itself from each configuration method, enabling
   a fluent, expressive chain:
   ```
   S3Client s3Client = S3Client.builder()
       .region(Region.EU_NORTH_1)
       .credentialsProvider(provider)
       .httpClient(httpClient)
       .build();
   ```
   
   This reads naturally like English: "Create S3Client with region..., 
   credentials..., HTTP client..., then build."

4. IMMUTABILITY OF CREATED OBJECTS
   Once .build() is called, the S3Client is immutable and thread-safe:
   ```
   S3Client s3Client = S3Client.builder()
       .region(Region.EU_NORTH_1)
       .build();
   // s3Client cannot be modified - safe for concurrent access
   ```
   
   The S3ClientBuilder is mutable during construction, but final S3Client
   cannot be changed. This ensures thread safety across multiple threads
   using the same client.

5. VALIDATION AT BUILD TIME
   The builder can validate configuration before creating the object:
   ```
   S3Client s3Client = S3Client.builder()
       .region(Region.EU_NORTH_1)
       .build();  // Validates that region is set
   ```
   
   If required parameters are missing, build() throws an exception with
   a clear error message, rather than creating a broken object.

6. STEP-BY-STEP CONSTRUCTION
   Complex objects can be configured step-by-step:
   ```
   S3ClientBuilder builder = S3Client.builder();
   builder.region(Region.EU_NORTH_1);
   
   if (customCredentials != null) {
       builder.credentialsProvider(customCredentials);
   }
   
   if (customHttpClient != null) {
       builder.httpClient(customHttpClient);
   }
   
   S3Client s3Client = builder.build();
   ```
   
   This allows conditional configuration based on runtime logic.

EXAMPLES FROM OUR LAB:

Step 2 (CreateS3Buckets.java):
```
S3Client s3Client = S3Client.builder()
    .region(region)
    .build();
```
Simple, focused - only configured what was needed.

Step 6 (LatencyMeasurementS3.java):
```
for (Map.Entry<String, String> entry : regionBuckets.entrySet()) {
    String regionString = entry.getKey();
    Region region = Region.of(regionString);
    S3Client s3Client = S3Client.builder()
        .region(region)
        .build();
    // Use client
    s3Client.close();
}
```
The builder cleanly configures different clients for different regions.

CONCLUSION:
The Builder Pattern is beneficial because it:
1. Handles optional parameters elegantly
2. Makes code highly readable and self-documenting
3. Enables method chaining for fluent APIs
4. Ensures object immutability after creation
5. Allows compile-time validation of configuration
6. Supports conditional and step-by-step construction

It's an industry best practice for complex object creation and is used
throughout the AWS SDK.

===========================================================================
Question 3: What are the key differences between the request/response 
            patterns for Create, Read, List, and Delete operations?
===========================================================================

Think about:
- Input parameters for each operation
- Output/response types
- Error conditions specific to each operation
- Idempotency and side effects

Your Answer:

Each S3 operation (Create, Read, List, Delete) follows the SDK pattern
but with distinct characteristics:

CREATE OPERATION (CreateBucket - Step 2)
---------------------------------------
Request:
- CreateBucketRequest: specifies bucket name and region
- No request body (metadata only)
- Example:
  ```
  CreateBucketRequest request = CreateBucketRequest.builder()
      .bucket(bucketName)
      .createBucketConfiguration(config)
      .build();
  ```

Response:
- CreateBucketResponse: contains location URI
- HTTP 200 success
- Response:
  ```
  CreateBucketResponse response = s3Client.createBucket(request, config);
  System.out.println(response.location());  // http://bucket.s3.amazonaws.com/
  ```

Upload (PutObject - Step 4)
- CreateBucketRequest: specifies bucket, key
- RequestBody: file content (required!)
- Returns: CreateBucketResponse with ETag
- Critical detail: Must provide both Request AND RequestBody

Error Conditions:
- BucketAlreadyOwnedByYou: bucket exists (already created)
- BucketAlreadyExists: name taken by another account
- InvalidBucketName: violates naming rules
- Region mismatch: bucket in different region

Idempotency:
- NOT idempotent: creating same bucket twice fails
- Second call throws BucketAlreadyOwnedByYou exception

---

READ OPERATION (GetObject / Download - Step 6)
---------------------------------------------
Request:
- GetObjectRequest: specifies bucket and key (object name)
- No request body
- Example:
  ```
  GetObjectRequest request = GetObjectRequest.builder()
      .bucket(bucketName)
      .key(objectKey)
      .build();
  ```

Response:
- InputStream: file content as stream (NOT response object)
- HTTP 200 success
- Critical: Must manually read InputStream and write to file
- Response:
  ```
  InputStream stream = s3Client.getObject(request);
  try (FileOutputStream fos = new FileOutputStream(localPath)) {
      byte[] buffer = new byte[1024];
      int len;
      while ((len = stream.read(buffer)) > 0) {
          fos.write(buffer, 0, len);
      }
  }
  ```

Error Conditions:
- NoSuchKey: object doesn't exist (404)
- NoSuchBucket: bucket doesn't exist
- AccessDenied: lack permissions to read
- NOT an error - just returns empty stream

Idempotency:
- Idempotent: downloading same object multiple times succeeds
- Returns same content every time

Key Difference from Create/Delete:
- Returns streaming response (InputStream), not a response object
- Must handle streaming manually
- No response metadata (like ETag)

---

LIST OPERATION (ListBuckets / ListObjects - Steps 3, 5)
-----------------------------------------------------
Request (List Buckets):
- ListBucketsRequest: empty, no parameters
- Example:
  ```
  ListBucketsRequest request = ListBucketsRequest.builder().build();
  ```

Request (List Objects):
- ListObjectsV2Request: specifies bucket
- Optional: prefix, delimiter for filtering
- Example:
  ```
  ListObjectsV2Request request = ListObjectsV2Request.builder()
      .bucket(bucketName)
      .maxKeys(100)  // pagination
      .build();
  ```

Response (List Buckets):
- ListBucketsResponse: contains list of Bucket objects
- Each Bucket has: name, creationDate, owner
- Response:
  ```
  ListBucketsResponse response = s3Client.listBuckets(request);
  List<Bucket> buckets = response.buckets();
  for (Bucket bucket : buckets) {
      System.out.println(bucket.name());
  }
  ```

Response (List Objects):
- ListObjectsV2Response: contains list of S3Object objects
- Each S3Object has: key, size, lastModified, eTag, storageClass
- Response:
  ```
  ListObjectsV2Response response = s3Client.listObjectsV2(request);
  List<S3Object> objects = response.contents();
  for (S3Object obj : objects) {
      System.out.println(obj.key() + " (" + obj.size() + " bytes)");
  }
  ```

Pagination:
- ListObjectsV2Response includes: isTruncated, nextContinuationToken
- For large lists, must use continuation tokens to fetch next page
- Example:
  ```
  List<S3Object> allObjects = new ArrayList<>();
  String token = null;
  do {
      ListObjectsV2Request req = ListObjectsV2Request.builder()
          .bucket(bucket)
          .continuationToken(token)
          .build();
      ListObjectsV2Response resp = s3Client.listObjectsV2(req);
      allObjects.addAll(resp.contents());
      token = resp.nextContinuationToken();
  } while (resp.isTruncated());
  ```

Error Conditions:
- NoSuchBucket: bucket doesn't exist
- AccessDenied: lack permissions to list
- Empty list: NOT an error - just no objects/buckets

Idempotency:
- Idempotent: listing same bucket multiple times returns same list
- Safe to call repeatedly

---

DELETE OPERATION (DeleteObject - Step 5)
---------------------------------------
Request:
- DeleteObjectRequest: specifies bucket and key
- No request body
- Example:
  ```
  DeleteObjectRequest request = DeleteObjectRequest.builder()
      .bucket(bucketName)
      .key(objectKey)
      .build();
  ```

Response:
- DeleteObjectResponse: contains HTTP status and metadata
- Response:
  ```
  DeleteObjectResponse response = s3Client.deleteObject(request);
  System.out.println(response.sdkHttpResponse().statusCode());  // 204
  System.out.println(response.deleteMarker());  // false (non-versioned)
  ```

Status Codes:
- HTTP 204 No Content: object was deleted
- HTTP 200 OK: object didn't exist (still returns success!)
- Both are considered successful

Error Conditions:
- AccessDenied: lack permissions to delete
- NoSuchBucket: bucket doesn't exist
- NoSuchKey: NOT an error! Returns 200/204

Idempotency:
- Idempotent: deleting same object twice both succeed
- First deletion removes object
- Second deletion succeeds (returns 200) even though object gone
- This is intentional - delete is idempotent operation

Key Difference:
- Returns 200/204 even if object didn't exist
- No "object not found" error
- Designed for idempotent, safe deletion

---

COMPARISON TABLE
===========================================================================

Operation | Request Type | Response Type | Idempotent | Repeatable
----------|--------------|---------------|-----------|----------
Create    | Specific     | Response obj  | NO        | Error on repeat
PutObject | Specific+Body| Response obj  | YES       | Overwrites
Read      | Specific     | InputStream   | YES       | Same content
List      | Generic      | Response obj  | YES       | Same list
Delete    | Specific     | Response obj  | YES       | Always succeeds

---

KEY INSIGHTS FROM OUR LAB:

1. CREATE/UPDATE are different operations
   - CreateBucket: fails if exists
   - PutObject: overwrites if exists (idempotent)

2. READ operations return streams, not objects
   - GetObject returns InputStream, not GetObjectResponse
   - Must handle streaming manually

3. LIST operations handle pagination
   - Not all objects/buckets returned in one call
   - Must check isTruncated and use continuation tokens

4. DELETE is forgiving
   - Succeeds even if object doesn't exist
   - Perfect for cleanup operations
   - Idempotent design

5. Error handling varies
   - Create: throws if already exists
   - Delete: succeeds even if doesn't exist
   - List: returns empty list, not error

CONCLUSION:
The request/response patterns differ significantly based on operation type:
- CREATE: specific request, fails if exists
- READ: specific request, returns stream
- LIST: generic request, returns collections with pagination
- DELETE: specific request, idempotent (always succeeds)

Understanding these patterns is crucial for using the AWS SDK effectively
and building robust cloud applications.

===========================================================================
Question 4: How would you optimize the latency measurement test for more 
            accurate results?
===========================================================================

Think about:
- Multiple iterations and averages
- Warming up connections
- Network conditions
- File sizes and their impact
- Statistical analysis
- Time measurement precision

Your Answer:

Our latency measurement in Step 6 provided initial data, but produced
high variability (683 ms difference). To get more accurate, statistically
significant results:

CURRENT LIMITATIONS:
------
Our test ran:
- Single upload + download per region (1 iteration)
- 1 MB file size (might not be representative)
- Measured total elapsed time with System.currentTimeMillis() (1 ms precision)
- No warm-up runs
- Network in potentially variable state

Results showed:
- eu-central-1: 905 ms (fastest)
- eu-west-1: 1263 ms
- eu-north-1: 1588 ms (slowest)
- 75.47% difference - seems large, suggests high variability

---

OPTIMIZATION 1: MULTIPLE ITERATIONS WITH STATISTICS
-------------------------------------------------
Instead of single run:

```java
int iterations = 10;
Map<String, List<Long>> uploadTimes = new HashMap<>();
Map<String, List<Long>> downloadTimes = new HashMap<>();

for (String regionString : regions) {
    List<Long> uploads = new ArrayList<>();
    List<Long> downloads = new ArrayList<>();
    
    for (int i = 0; i < iterations; i++) {
        long uploadMs = uploadFileToS3(...);
        long downloadMs = downloadFileFromS3(...);
        uploads.add(uploadMs);
        downloads.add(downloadMs);
    }
    
    uploadTimes.put(regionString, uploads);
    downloadTimes.put(regionString, downloads);
}

// Calculate statistics
for (String region : regions) {
    List<Long> uploads = uploadTimes.get(region);
    long min = Collections.min(uploads);
    long max = Collections.max(uploads);
    double avg = uploads.stream().mapToLong(Long::longValue).average().orElse(0);
    long median = uploads.stream().sorted().collect(...).get(uploads.size()/2);
    double stdDev = calculateStandardDeviation(uploads);
    
    System.out.printf("%s Upload: min=%d, max=%d, avg=%.2f, median=%d, stddev=%.2f\n",
        region, min, max, avg, median, stdDev);
}
```

Benefits:
- Median is more resistant to outliers than average
- Standard deviation shows consistency
- Min/max shows best/worst case scenarios
- 10+ iterations reduces impact of single network anomaly

Expected improvement:
- Variability reduced due to averaging
- Statistical significance increases
- More representative of typical performance

---

OPTIMIZATION 2: WARM-UP RUNS
--------------------------
First connections are slower (SSL handshake, DNS lookup, etc.).
Add warm-up runs before measurement:

```java
// Warm-up phase (not counted)
System.out.println("Warming up connections...");
for (int warmup = 0; warmup < 2; warmup++) {
    for (String region : regions) {
        uploadFileToS3(...);      // Warm up upload
        downloadFileFromS3(...);  // Warm up download
    }
}

// Now do actual measurements (starting fresh)
System.out.println("Starting measurements...");
// ... actual test code ...
```

Benefits:
- First run always slower (connection setup)
- Warm-up ensures connection pooling is ready
- Subsequent runs measure steady-state performance
- More realistic of actual application behavior

Impact on results:
- eu-north-1 might improve significantly (reduced overhead)
- Overall latencies might decrease
- Variance between regions might become clearer

---

OPTIMIZATION 3: PRECISE TIME MEASUREMENT
---------------------------------------
System.currentTimeMillis() has 1ms precision (Windows can be 15ms).
Use System.nanoTime() for microsecond precision:

```java
// Instead of:
long startTime = System.currentTimeMillis();
// ... operation ...
long endTime = System.currentTimeMillis();
long elapsed = endTime - startTime;  // milliseconds

// Use:
long startTime = System.nanoTime();
// ... operation ...
long endTime = System.nanoTime();
long elapsed = (endTime - startTime) / 1_000_000;  // convert to ms

// Or keep in nanoseconds for higher precision
long elapsedNanos = endTime - startTime;
double elapsedMs = elapsedNanos / 1_000_000.0;
```

Benefits:
- Nanosecond precision vs millisecond
- Better for sub-millisecond operations
- Not affected by system clock adjustments
- More accurate for short operations

---

OPTIMIZATION 4: VARIABLE FILE SIZES
---------------------------------
Single 1 MB test might not be representative.
Test multiple file sizes to see behavior:

```java
int[] fileSizes = {
    100 * 1024,           // 100 KB - small
    1024 * 1024,          // 1 MB - medium
    10 * 1024 * 1024,     // 10 MB - large
    100 * 1024 * 1024     // 100 MB - very large
};

for (int fileSize : fileSizes) {
    System.out.println("Testing with " + formatSize(fileSize) + " files");
    createTestFile(testFile, fileSize);
    
    for (String region : regions) {
        long uploadTime = uploadFileToS3(...);
        long downloadTime = downloadFileFromS3(...);
        
        double uploadThroughput = (fileSize / 1024.0) / (uploadTime / 1000.0);
        double downloadThroughput = (fileSize / 1024.0) / (downloadTime / 1000.0);
        
        System.out.printf("%s: upload=%.2f KB/s, download=%.2f KB/s\n",
            region, uploadThroughput, downloadThroughput);
    }
}
```

Benefits:
- Shows how file size affects performance
- Small files: overhead dominates
- Large files: bandwidth dominates
- Real-world scenarios use varying file sizes

Expected insights:
- Small files might show similar latency across regions
- Large files might show significant throughput differences
- Network overhead becomes clearer with multiple sizes

---

OPTIMIZATION 5: NETWORK CONDITION ANALYSIS
-----------------------------------------
Add network metrics alongside performance:

```java
// Measure network metrics
class NetworkMetrics {
    long packetLoss;
    long latency;  // ping time
    long jitter;   // variance in latency
    
    void measure(String region) {
        // Run ping to S3 endpoint
        // Measure round-trip time
        // Calculate jitter from multiple pings
    }
}

// Correlate with S3 performance
for (String region : regions) {
    NetworkMetrics metrics = new NetworkMetrics();
    metrics.measure(region);
    
    long uploadTime = uploadFileToS3(...);
    
    System.out.printf("%s: latency=%dms, jitter=%dms, upload=%dms\n",
        region, metrics.latency, metrics.jitter, uploadTime);
}
```

Benefits:
- Explains latency differences
- High jitter correlates with variable upload times
- Identifies network-specific issues
- Helps distinguish network vs AWS factors

---

OPTIMIZATION 6: STATISTICAL SIGNIFICANCE TESTING
-----------------------------------------------
Determine if differences are real or just noise:

```java
// Use paired t-test to compare regions
class StatisticalTest {
    static double calculateTTest(List<Long> group1, List<Long> group2) {
        double mean1 = group1.stream().mapToLong(Long::longValue).average().orElse(0);
        double mean2 = group2.stream().mapToLong(Long::longValue).average().orElse(0);
        double var1 = variance(group1, mean1);
        double var2 = variance(group2, mean2);
        int n1 = group1.size();
        int n2 = group2.size();
        
        double t = (mean1 - mean2) / Math.sqrt(var1/n1 + var2/n2);
        // Look up p-value from t-distribution
        return t;
    }
}

// Results interpretation:
// If |t-value| > critical value for p=0.05:
//   Difference is statistically significant
// If |t-value| < critical value:
//   Difference might be just noise
```

Benefits:
- Determines if eu-central-1 is truly faster
- 75% difference might not be statistically significant
- Avoids false conclusions
- Supports decision-making

---

OPTIMIZATION 7: ENVIRONMENT ISOLATION
----------------------------------
Control variables that affect results:

```
Before test:
1. Stop other network activity
2. Minimize local CPU usage
3. Clear OS file caches
4. Ensure stable AWS infrastructure

During test:
1. Run during consistent network times
2. Avoid high-traffic periods (midday in US)
3. Don't run other applications
4. Monitor system resources

After test:
1. Run at different times of day
2. Run from different networks
3. Run on different EC2 instance types
4. Compare results
```

---

OPTIMIZATION 8: BENCHMARK FRAMEWORK
---------------------------------
Use JMH (Java Microbenchmark Harness):

```java
// Add JMH dependency to pom.xml
// Provides statistical rigor for Java benchmarks

@Benchmark
@BenchmarkMode(Mode.AverageTime)
@OutputTimeUnit(TimeUnit.MILLISECONDS)
public void uploadToEuNorth1() {
    uploadFileToS3(s3Client, bucket, file);
}

@Benchmark
public void uploadToEuWest1() {
    uploadFileToS3(s3Client, bucket, file);
}

// Run: java -jar benchmarks.jar
```

Benefits:
- Professional-grade measurements
- Handles JVM warmup, GC tuning
- Statistically robust results
- Integrated reporting

---

SUMMARY OF IMPROVEMENTS
===========================================================================

Current Results:
- eu-central-1: 905 ms (fastest)
- eu-west-1: 1263 ms
- eu-north-1: 1588 ms
- Single run, high variance

Optimized Results (expected):
- Median instead of single value
- Statistical significance testing
- Multiple file sizes
- Reduced variance
- Better conclusions

KEY METRICS TO TRACK:
1. Latency (ms) - raw time
2. Throughput (KB/s) - efficiency
3. Consistency (std dev) - reliability
4. Percentiles (p50, p95, p99) - distribution
5. Error rate - failures

BEST PRACTICES:
1. Run 10+ iterations minimum
2. Use warm-up runs
3. Measure with nanosecond precision
4. Test variable file sizes
5. Control environment variables
6. Use statistical analysis
7. Repeat at different times
8. Use professional tools (JMH)

CONCLUSION:
Our initial test showed eu-central-1 as fastest, but accurate conclusions
require multiple iterations, statistical analysis, and control of external
variables. The 75% difference is interesting but might be overstated due
to measurement variance. Proper optimization techniques would confirm if
Frankfurt truly offers 75% better performance or if the difference is smaller.

For production decisions, always use comprehensive benchmarking, not
single test runs.

===========================================================================
