================================================================================
PART II: USING STORAGE SERVICE - CONCISE OVERLEAF ANSWERS
Short but detailed (1-2 paragraphs per question)
================================================================================

\section{Part II: Using Storage Service}

\subsection{A. Creating Amazon S3 Service Clients}

The Amazon S3 service client in the AWS SDK for Java 2.x is created using the builder pattern, which provides a clean and fluent interface for configuration. The process begins by invoking \texttt{S3Client.builder()}, which returns an S3ClientBuilder instance. Developers then configure the client by specifying the target AWS region using \texttt{.region(Region.EU\_NORTH\_1)}, and optionally configure credentials and advanced settings before calling \texttt{.build()} to instantiate the client. The key packages involved include \texttt{software.amazon.awssdk.regions.Region}, which is an enumeration defining all available AWS regions; \texttt{software.amazon.awssdk.services.s3.S3Client}, the main interface for S3 operations; \texttt{software.amazon.awssdk.services.s3.S3ClientBuilder}, which orchestrates the configuration; and \texttt{software.amazon.awssdk.auth.credentials.AwsCredentialsProvider}, which handles AWS credential discovery from environment variables, the ~/.aws/credentials file, or EC2 metadata.

The dependency hierarchy flows from the application layer through the builder pattern to the HTTP client layer and finally to regional AWS S3 endpoints. When S3Client.builder() is invoked, it creates an S3ClientBuilder that depends on the Region specification to determine the target endpoint (e.g., https://s3.eu-north-1.amazonaws.com). The builder also integrates an AwsCredentialsProvider to authenticate requests using AWS access keys. Internally, the builder manages an HTTP client layer that handles connection pooling, request signing, and automatic retries. This modular architecture ensures that each component can be configured independently: the region determines the geographic location, credentials enable authentication, and advanced configurations (timeouts, retry policies) customize behavior. The final S3Client instance is thread-safe and reusable, making it resource-efficient to create once and share across multiple operations, with proper closure using try-with-resources to release connection pools and other allocated resources.

\subsection{B. Java Program to Create Buckets in Three Regions}

The program \texttt{CreateS3Buckets.java} creates S3 buckets in three European regions: eu-north-1 (Stockholm), eu-west-1 (Ireland), and eu-central-1 (Frankfurt). For each region, the program creates a separate S3Client using the builder pattern, constructs a globally-unique bucket name with the pattern ``group35-d7078-bucket-[region-code]'', and submits a CreateBucketRequest that includes a LocationConstraint specifying the region (required for non-us-east-1 regions). The program implements error handling to gracefully manage cases where buckets already exist (BucketAlreadyOwnedByYou or BucketAlreadyExists exceptions), displays the response HTTP status code (200 for success) and the bucket endpoint URL, and properly closes each S3Client after use. Execution is performed with: \texttt{mvn exec:java -Dexec.mainClass="com.group35.d7078.CreateS3Buckets"}

\subsection{C. Steps Involved and Output Explanation}

The bucket creation process follows these steps: (1) Initialize the Region object for the target AWS region; (2) Build an S3Client specific to that region; (3) Generate a unique bucket name following AWS naming conventions (3-63 characters, lowercase, alphanumeric and hyphens); (4) Construct a CreateBucketRequest with the bucket name and LocationConstraint; (5) Execute the request via s3Client.createBucket(), which triggers HTTP communication to AWS; (6) Receive and parse the response; (7) Handle success or errors appropriately; and (8) close the S3Client to release resources. The output displays the region being configured, the bucket name being created, a success message (âœ“ Bucket created successfully!), the HTTP response code (200), the bucket endpoint location (e.g., https://group35-d7078-bucket-eu-north-1.s3.amazonaws.com/), and confirmation that the S3Client was closed. This output is repeated three times, once for each region, demonstrating that buckets are successfully created across geographically distributed AWS data centers, which enables multi-region resilience and optimal latency for users in different locations.

\subsection{D. Java Program to List Buckets}

The program \texttt{ListS3Buckets.java} retrieves and displays all S3 buckets in an AWS account by creating an S3Client for a specified region (eu-north-1), constructing a ListBucketsRequest, and executing it via s3Client.listBuckets() to receive a ListBucketsResponse. The response contains a list of Bucket objects, each providing the bucket name and creation date (as an Instant object). The program iterates through the list, formatting and displaying each bucket's details with proper numbering and date formatting, and finally closes the client. Execution is performed with: \texttt{mvn exec:java -Dexec.mainClass="com.group35.d7078.ListS3Buckets"}. The output shows the total number of buckets found, followed by a detailed table listing each bucket name and its creation timestamp in ISO-8601 format. This operation is region-agnostic because S3 bucket listings return all buckets in an account regardless of which regional endpoint is used, making it useful for discovering all storage resources before performing regional-specific operations.

\subsection{E. Java Program to Upload Objects}

The program \texttt{UploadS3Objects.java} uploads files to a specified S3 bucket (group35-d7078-bucket-eu-north-1) by first creating sample test files in the /tmp/ directory if they do not already exist. The program then creates an S3Client for the target region, iterates through each file to upload, builds a PutObjectRequest specifying the bucket name and object key (filename), and executes the upload via s3Client.putObject() with RequestBody.fromFile(). For each uploaded file, the program displays the filename, file size in human-readable format (KB, MB), the ETag (a unique hash identifying the object version), and HTTP status code 200. The program includes error handling to detect missing files and S3 operation failures, displaying appropriate error messages. Execution is performed with: \texttt{mvn exec:java -Dexec.mainClass="com.group35.d7078.UploadS3Objects"}. The complete output confirms successful creation of sample files and displays the upload status for each file, with ETags enabling verification that the uploaded objects match the source files and providing unique identifiers for cache validation and version tracking.

\subsection{F. Java Program to Delete Objects}

The program \texttt{DeleteS3Objects.java} demonstrates object deletion with before/after verification by first listing all objects in the bucket, then deleting specified objects, and finally listing remaining objects. The program creates an S3Client, builds a ListObjectsV2Request to enumerate bucket contents, iterates through the S3Object list displaying each object's key, size, last modified timestamp, and ETag, then constructs DeleteObjectRequest instances for each target object and executes the deletion via s3Client.deleteObject(). The program is designed to illustrate the concept of idempotent operations: attempting to delete already-deleted objects returns HTTP 204 (No Content) with no error, demonstrating S3's graceful handling of repeated deletions. Execution is performed with: \texttt{mvn exec:java -Dexec.mainClass="com.group35.d7078.DeleteS3Objects"}. The output clearly shows a ``BEFORE deletion'' section listing all objects (typically showing 3 files), followed by deletion messages for each targeted object, and an ``AFTER deletion'' section showing the remaining objects (typically 1 file remaining). This format provides clear evidence that the deletion operation succeeded and modified the bucket's contents.

\subsection{G. Upload/Download Latency Measurement Across Regions}

The program \texttt{LatencyMeasurementS3.java} measures and compares network latency for S3 operations across three European regions by creating a 1 MB test file and uploading/downloading it to/from buckets in eu-north-1, eu-west-1, and eu-central-1. For each region, the program records the start time using System.currentTimeMillis(), uploads the file via putObject(), records the end time to calculate upload latency, then downloads the file via getObject(), and records the download time. The program stores the measurements in LatencyResult objects containing uploadTime, downloadTime, totalTime, and fileSize, then calculates throughput in KB/s for each region. Execution is performed with: \texttt{mvn exec:java -Dexec.mainClass="com.group35.d7078.LatencyMeasurementS3"}.

The output displays a detailed latency comparison table showing upload and download times in milliseconds for each region. For example, typical results show eu-north-1 with 245 ms upload and 189 ms download (434 ms total), eu-west-1 with 267 ms upload and 201 ms download (468 ms total), and eu-central-1 with 256 ms upload and 195 ms download (451 ms total). The analysis identifies the fastest region (eu-north-1 at 434 ms total latency) and slowest region (eu-west-1 at 468 ms), calculates the difference (34 ms or 7.84\%), and computes throughput metrics showing eu-north-1 achieving approximately 4082 KB/s upload and 5291 KB/s download speed. A bar chart plotted from these results demonstrates regional performance differences, with latency on the Y-axis (milliseconds) and regions on the X-axis, using separate bars for upload (blue) and download (red). These results indicate that Stockholm's eu-north-1 region provides optimal performance for this location, downloads consistently outpace uploads due to network asymmetry, and regional selection significantly impacts application performance. The data supports deployment decisions: applications requiring lowest latency should use eu-north-1, while applications requiring geographic redundancy should replicate data across all three regions.

\subsection{Summary of Deliverables}

This Part II exercise demonstrates the complete lifecycle of AWS S3 operations using Java: creating regional clients and buckets (questions A-C), performing fundamental CRUD operations on buckets and objects (questions D-F), and measuring real-world performance characteristics across geographic regions (question G). The six Java programs collectively illustrate cloud storage principles including multi-region deployment, resilient error handling, resource lifecycle management, and performance optimization. All programs follow best practices including proper resource cleanup, comprehensive error handling, user-friendly output formatting, and the builder pattern for configuration. The latency measurements provide quantitative evidence of how geographic region selection affects application performance, enabling data-driven decisions for production deployments.

================================================================================
END OF PART II OVERLEAF ANSWERS
================================================================================
