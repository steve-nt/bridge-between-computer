================================================================================
D7078E CLOUD SECURITY - IMPLEMENTATION GUIDE SUMMARY
================================================================================

You asked: "How should we implement the following tasks?"

ANSWER: Complete Tasks 5 & 6 to demonstrate automatic failover and recovery
        with full audit trail.

================================================================================
TASK 5: ASG Activity Log Screenshot (Scale-out to 3 + Replacements)
================================================================================

WHAT TO DO:
1. Wait until ASG reaches 3 instances (from Task 4 load generators)
2. Trigger controlled failure simulation on one instance
3. Observe automatic health check failure detection
4. Watch ASG automatically launch replacement instance
5. Document recovery with screenshots and metrics

HOW TO TRIGGER FAILURE (Pick One):

  OPTION A (RECOMMENDED): SSM Stress Command
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Run: aws ssm send-command --instance-ids i-0f9087a79628fd056 \
         --document-name "AWS-RunShellScript" \
         --parameters 'commands=["stress-ng -c 0 -l 90 -t 120s"]'
  
  Why: Simple, safe, time-limited (120 seconds), fully auditable

  OPTION B: AWS FIS Experiment
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Use: AWS Console > Fault Injection Simulator > Create Experiment
  
  Why: Enterprise-grade, designed for chaos testing, reversible

EXPECTED TIMELINE:
  Minute 0:     Stress command starts â†’ CPU spikes to 90%
  Minute 0-1:   Health check fails â†’ Instance marked unhealthy
  Minute 1:     ASG detects unhealthy instance
  Minute 1-2:   ASG launches replacement instance
  Minute 2:     Stress command ends (120s timeout)
  Minute 2-3:   Replacement instance boots and joins Target Group
  Minute 3+:    Old instance terminates, system recovered
  
  Total recovery: ~4 minutes, automatic, no manual intervention

WHAT TO CAPTURE (Screenshots):
  â˜ Before: 3 instances healthy, normal CPU
  â˜ During health failure: HealthyHostCount drops 3â†’2
  â˜ During replacement: New instance in "Pending" state
  â˜ During recovery: New instance passing health checks
  â˜ After recovery: HealthyHostCount back to 3, old instance terminated

================================================================================
TASK 6: FIS/SSM Command Logs + CloudTrail Evidence
================================================================================

WHAT TO COLLECT:

1. SSM Command Log
   File: ssm_command_log.json
   How:  aws ssm get-command-invocation --command-id <ID> --instance-id <ID>
   Shows: Command execution, timestamps, success/failure

2. CloudTrail Events (AWS Audit Trail)
   Files: cloudtrail_ssm_logs.json, cloudtrail_asg_logs.json
   How:   aws cloudtrail lookup-events --lookup-attributes ...
   Shows: Who executed what, when, from where, with what parameters

3. ASG Activity History
   File: asg_activity_log.json or .csv
   How:  aws autoscaling describe-scaling-activities ... 
         OR: AWS Console > ASG > Activity tab > Export
   Shows: Health failures, instance launches, terminations, timestamps

4. CloudWatch Metrics
   Files: cloudwatch_cpu.json, cloudwatch_healthy_hosts.json
   How:   aws cloudwatch get-metric-statistics ... (for time range during failure)
   Shows: CPU spike, HealthyHostCount drops/recovers, RequestCount changes

5. Timeline Document
   File: Your custom document with exact timestamps
   Shows: Complete failureâ†’recovery timeline with all key events

WHY COLLECT THIS EVIDENCE?
  âœ“ Proves failure was simulated (SSM/FIS logs)
  âœ“ Proves all actions are auditable (CloudTrail)
  âœ“ Proves ASG responded automatically (Activity logs)
  âœ“ Proves system recovered (CloudWatch metrics)
  âœ“ Demonstrates compliance & auditability (CloudTrail + timestamps)

================================================================================
YOUR DELIVERABLES CHECKLIST
================================================================================

TASK 5 DELIVERABLES:
  â˜ 5+ screenshots showing:
    â”œâ”€ Before: All 3 instances healthy
    â”œâ”€ During: Health failure, replacement launching
    â”œâ”€ After: Recovery complete, all 3 healthy again
    â””â”€ CloudWatch showing CPU spike and recovery
  
  â˜ Timeline document with exact timestamps:
    â”œâ”€ When stress started
    â”œâ”€ When health check failed
    â”œâ”€ When ASG launched replacement
    â”œâ”€ When recovery completed
    â””â”€ Total recovery time (should be ~4 minutes)

TASK 6 DELIVERABLES:
  â˜ SSM command log (JSON file)
  â˜ CloudTrail logs (JSON files):
    â”œâ”€ SSM SendCommand event
    â”œâ”€ ASG Launch event
    â””â”€ EC2 Terminate event
  â˜ ASG Activity history (JSON or CSV)
  â˜ CloudWatch metrics (JSON or CSV):
    â”œâ”€ CPU timeline
    â””â”€ HealthyHostCount timeline
  â˜ Analysis document explaining what the evidence shows

================================================================================
KEY FILES YOU HAVE
================================================================================

Main Implementation Guides:
  1. IMPLEMENTATION_TASKS_GUIDE.md
     â†’ Complete detailed guide with architecture diagrams
     â†’ Step-by-step instructions for Tasks 5 & 6
     â†’ Success criteria and troubleshooting

  2. TASK_5_6_QUICK_CHECKLIST.md
     â†’ Quick checklist format for fast execution
     â†’ Pre-flight checks
     â†’ Screenshot checklist
     â†’ Timing estimates

  3. COMMANDS_READY_TO_USE.md
     â†’ Copy-paste ready AWS CLI commands
     â†’ All templates with explanations
     â†’ No need to write commands from scratch

Existing Guides:
  4. TASK_5_FAILURE_SIMULATION.txt (original)
     â†’ 3 failure simulation methods explained
     â†’ Timeline and expectations
     
  5. SSM_SETUP_DETAILED.txt
     â†’ Complete IAM role setup for SSM access
     â†’ Required before FIS/SSM commands work

================================================================================
QUICK EXECUTION STEPS
================================================================================

STEP 1: Verify Setup (2 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Confirm 3 instances running in ASG
âœ“ Confirm all 3 instances "Healthy" in Target Group
âœ“ Confirm load generators running (traffic flowing)
âœ“ Confirm SSM role attached to instances (Fleet Manager shows "Online")
âœ“ Open CloudWatch dashboard for real-time monitoring

STEP 2: Execute Failure Simulation (2 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Use COMMANDS_READY_TO_USE.md:

  Method A (Simpler):
    Run: aws ssm send-command (with stress-ng command)
    Note: Command ID and timestamp
    Open: CloudWatch dashboard to watch failure

  Method B (Enterprise):
    Go to: Fault Injection Simulator
    Create: CPU stress experiment targeting your instances
    Start: Experiment, note timestamp
    Open: CloudWatch dashboard to watch failure

STEP 3: Monitor Failure & Recovery (7 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Watch in CloudWatch:
  0-1 min:  CPU spikes to 90%, HealthyHostCount drops 3â†’2
  1-2 min:  ASG Activity shows "Launching 1 instances"
  2-3 min:  New instance boots and joins (HealthyHostCount: 2â†’3)
  3-5 min:  Old instance terminates, system normalized

Take screenshots at each major milestone.

STEP 4: Collect Evidence (10 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Use COMMANDS_READY_TO_USE.md Task 6 section:

  1. Export SSM command log
  2. Export CloudTrail events (3 exports)
  3. Export ASG activity
  4. Export CloudWatch metrics (2 exports)
  5. Verify all files

STEP 5: Create Analysis Document (5 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Write: What the evidence proves
  âœ“ System is resilient (survived single instance failure)
  âœ“ Recovery is automatic (no manual intervention)
  âœ“ Timeline is fast (~4 minutes)
  âœ“ All actions are auditable (CloudTrail proves it)
  âœ“ Meets production requirements

TOTAL TIME: ~30-35 minutes for both tasks

================================================================================
WHAT PROVES TASK 5 SUCCESS
================================================================================

Screenshots showing:
  âœ“ ASG Activity log with "Launching 1 instances" entry
  âœ“ "Health check failure detected" message
  âœ“ Instance count going from 3 â†’ 2 â†’ 3
  âœ“ New instance appearing in EC2 Instances
  âœ“ Old instance getting terminated

CloudWatch graphs showing:
  âœ“ CPU spike on one instance (90%+)
  âœ“ HealthyHostCount dropping (3 â†’ 2)
  âœ“ HealthyHostCount recovering (2 â†’ 3)
  âœ“ RequestCount dropping slightly then recovering
  âœ“ Complete timeline visible in one dashboard view

Timeline document showing:
  âœ“ Exact start time of failure
  âœ“ Exact time of health check failure
  âœ“ Exact time ASG launched replacement
  âœ“ Exact time recovery completed
  âœ“ Total recovery time: ~4 minutes

================================================================================
WHAT PROVES TASK 6 SUCCESS
================================================================================

SSM Command Log shows:
  âœ“ Command ID (proves command was sent)
  âœ“ Timestamp (proves when stress started)
  âœ“ Status: "Success" (proves command executed)
  âœ“ Output showing stress-ng executed

CloudTrail logs show:
  âœ“ SendCommand API call (SSM action)
  âœ“ Timestamp matching failure start
  âœ“ Username and source IP (who ran it)
  âœ“ RunInstances API call (ASG launching)
  âœ“ TerminateInstances API call (ASG cleanup)
  âœ“ Complete audit trail with signatures

ASG Activity shows:
  âœ“ Health check failure entry with timestamp
  âœ“ Instance removal entry
  âœ“ "Launching 1 instances" entry
  âœ“ "Successfully launched" entry
  âœ“ Exact timestamps matching timeline

CloudWatch metrics show:
  âœ“ CPU data points during failure window
  âœ“ HealthyHostCount data showing 3â†’2â†’3 transition
  âœ“ Timestamps matching all other evidence
  âœ“ Exportable as CSV for analysis

================================================================================
SUCCESS DEFINITION
================================================================================

You're done when:

TASK 5 COMPLETE:
  âœ“ 3 instances healthy in ASG
  âœ“ Failure triggered on one instance
  âœ“ Health check detected failure within 1 minute
  âœ“ ASG automatically launched replacement
  âœ“ System recovered to 3 healthy instances in ~4 minutes
  âœ“ Demonstrated with screenshots showing entire cycle

TASK 6 COMPLETE:
  âœ“ SSM command log exported
  âœ“ CloudTrail events exported (3+ files)
  âœ“ ASG activity exported
  âœ“ CloudWatch metrics exported
  âœ“ Timeline document created with exact timestamps
  âœ“ Analysis document explaining what evidence proves

BOTH TASKS COMPLETE:
  âœ“ Lab report includes all deliverables
  âœ“ Screenshots show failureâ†’recoveryâ†’recovery complete
  âœ“ Logs prove all actions are auditable
  âœ“ Timestamps prove recovery was fast and automatic
  âœ“ Ready to submit to instructor

================================================================================
WHERE TO START RIGHT NOW
================================================================================

1. READ THIS FIRST:
   â†’ IMPLEMENTATION_TASKS_GUIDE.md (main guide)

2. THEN USE THIS:
   â†’ TASK_5_6_QUICK_CHECKLIST.md (execute step-by-step)

3. FOR COMMANDS, USE THIS:
   â†’ COMMANDS_READY_TO_USE.md (copy-paste ready)

4. IF YOU GET STUCK:
   â†’ TASK_5_FAILURE_SIMULATION.txt (original detailed guide)
   â†’ SSM_SETUP_DETAILED.txt (if SSM setup needed)

================================================================================
TLDR - COMPLETE IN 5 STEPS
================================================================================

1. Verify 3 instances healthy (2 min)
2. Run SSM stress command on one instance (1 min)
3. Watch failure & recovery in CloudWatch (7 min)
4. Take screenshots during failure/recovery (automatic)
5. Export logs with AWS CLI commands (10 min)

Total: 30 minutes, demonstrates:
  âœ“ Auto-scaling works (Tasks 1-4)
  âœ“ Failure detection works
  âœ“ Auto-recovery works
  âœ“ System is resilient
  âœ“ All actions auditable

Result: Impressive lab report showing production-grade infrastructure!

================================================================================
FINAL TIPS
================================================================================

DO:
  âœ“ Keep CloudWatch dashboard open during Task 5
  âœ“ Note exact timestamps as events happen
  âœ“ Take many screenshots (can't have too many)
  âœ“ Collect all evidence right after (while fresh)
  âœ“ Review timeline document for accuracy
  âœ“ Explain in lab report why this proves resilience

DON'T:
  âœ— Skip SSM setup (required for failure simulation)
  âœ— Stop load generators during failure test
  âœ— Terminate ASG manually (let it auto-recover)
  âœ— Lose the evidence files (save backup copies)
  âœ— Ignore timestamps (they're critical)

Questions?
  â†’ See IMPLEMENTATION_TASKS_GUIDE.md (Troubleshooting section)
  â†’ See TASK_5_FAILURE_SIMULATION.txt (original guide)
  â†’ See COMMANDS_READY_TO_USE.md (command examples)

================================================================================
You're ready to go! Pick up IMPLEMENTATION_TASKS_GUIDE.md and start with
Task 5 execution. You've got this! ğŸš€
================================================================================
