================================================================================
TASK 4: IMPLEMENT & RUN INTERNAL LOAD GENERATORS
================================================================================

OBJECTIVE:
Deploy Python load generators in Docker containers to generate HTTP traffic
to the ALB. Monitor scaling as CPU rises and triggers auto-scaling policies.

REGION: eu-north-1
ALB DNS: D7078E-MINI-PROJECT-GROUP35-LB-8834940.eu-north-1.elb.amazonaws.com
ASG: D7078E-MINI-PROJECT-GROUP35-ASG
Max instances: 3

STATUS: Starting Task 4
Date: 2025-12-27 18:08:53 UTC

================================================================================
PREREQUISITES
================================================================================

Before starting, ensure you have:
✓ Python 3 installed on your local machine
✓ Docker installed and running
✓ Docker Compose installed
✓ ALB is responding to requests (from Task 2)
✓ Scaling policies and alarms are active (from Task 3)
✓ 1 instance currently running in the ASG

Quick verification:
- Test ALB: curl http://D7078E-MINI-PROJECT-GROUP35-LB-8834940.eu-north-1.elb.amazonaws.com/
- Check ASG: aws ec2 describe-instances --region eu-north-1 (should see 1 running)
- Check alarms: CloudWatch > Alarms (should see both alarms)

================================================================================
STEP 1: GET THE PYTHON LOAD GENERATOR SCRIPT (agent.py)
================================================================================

The lab already includes agent.py. Location:
C:\Users\snten\Desktop\bridge-between-computer\Mini D7078E\agent.py

If you don't have it, here's a simple implementation:

--- Create agent.py ---

cat > agent.py << 'EOF'
import asyncio
import aiohttp
import time
import argparse
from datetime import datetime

class LoadGenerator:
    def __init__(self, target_url, workers=2, rps=1, duration=300):
        self.target_url = target_url
        self.workers = workers
        self.rps = rps  # requests per second per worker
        self.duration = duration
        self.requests_sent = 0
        self.requests_success = 0
        self.requests_failed = 0
        self.start_time = None
        self.endpoints = ['/', '/metrics', '/burn']
    
    async def make_request(self, session, endpoint):
        try:
            url = self.target_url + endpoint
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    self.requests_success += 1
                else:
                    self.requests_failed += 1
                self.requests_sent += 1
                return True
        except Exception as e:
            self.requests_failed += 1
            self.requests_sent += 1
            return False
    
    async def worker(self, session):
        """Each worker sends requests at configured RPS"""
        delay = 1.0 / self.rps  # delay between requests
        while time.time() - self.start_time < self.duration:
            endpoint = self.endpoints[self.requests_sent % len(self.endpoints)]
            await self.make_request(session, endpoint)
            await asyncio.sleep(delay)
    
    async def run(self):
        """Run the load generator with multiple workers"""
        self.start_time = time.time()
        connector = aiohttp.TCPConnector(limit=100)
        
        async with aiohttp.ClientSession(connector=connector) as session:
            tasks = [self.worker(session) for _ in range(self.workers)]
            await asyncio.gather(*tasks)
        
        elapsed = time.time() - self.start_time
        print(f"\n[{datetime.now()}] Load generation complete!")
        print(f"Duration: {elapsed:.1f} seconds")
        print(f"Total requests sent: {self.requests_sent}")
        print(f"Successful: {self.requests_success}")
        print(f"Failed: {self.requests_failed}")
        print(f"Actual RPS: {self.requests_sent / elapsed:.2f}")

async def main():
    parser = argparse.ArgumentParser(description='D7078E Load Generator')
    parser.add_argument('--url', required=True, help='Target URL (e.g., http://alb-dns/)')
    parser.add_argument('--workers', type=int, default=2, help='Number of concurrent workers')
    parser.add_argument('--rps', type=float, default=1, help='Requests per second per worker')
    parser.add_argument('--duration', type=int, default=300, help='Duration in seconds')
    
    args = parser.parse_args()
    
    print(f"[{datetime.now()}] Starting load generator")
    print(f"Target: {args.url}")
    print(f"Workers: {args.workers}")
    print(f"RPS per worker: {args.rps}")
    print(f"Total RPS: {args.workers * args.rps}")
    print(f"Duration: {args.duration} seconds")
    
    generator = LoadGenerator(
        target_url=args.url,
        workers=args.workers,
        rps=args.rps,
        duration=args.duration
    )
    await generator.run()

if __name__ == '__main__':
    asyncio.run(main())
EOF

Save as: agent.py

================================================================================
STEP 2: CREATE DOCKERFILE
================================================================================

cat > Dockerfile << 'EOF'
FROM python:3.11-slim

WORKDIR /app

COPY agent.py .

RUN pip install aiohttp

ENTRYPOINT ["python", "agent.py"]
EOF

Save as: Dockerfile

================================================================================
STEP 3: CREATE DOCKER-COMPOSE.YML
================================================================================

cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  agent1:
    build: .
    container_name: load-generator-agent1
    environment:
      - TARGET_URL=http://D7078E-MINI-PROJECT-GROUP35-LB-8834940.eu-north-1.elb.amazonaws.com/
    command: >
      --url http://D7078E-MINI-PROJECT-GROUP35-LB-8834940.eu-north-1.elb.amazonaws.com/
      --workers 2
      --rps 1
      --duration 600
    networks:
      - load-gen-network

networks:
  load-gen-network:
    driver: bridge
EOF

Save as: docker-compose.yml

================================================================================
STEP 4: BUILD DOCKER IMAGE
================================================================================

Command:
docker build -t d7078e-load-gen .

Expected output:
[+] Building 10.2s (7/7) FINISHED
 => [internal] load build context
 => [1/7] FROM python:3.11-slim
 => [2/7] WORKDIR /app
 => [3/7] COPY agent.py .
 => [4/7] RUN pip install aiohttp
 => exporting to image
 => => naming to docker.localized:latest

Result: ✓ Image built successfully

================================================================================
STEP 5: RUN LOAD GENERATOR - PHASE 1 (LOW LOAD)
================================================================================

Objective: Start with LOW load to establish baseline, then ramp up.

Command:
docker-compose up --scale agent1=1

This runs:
- 1 container
- 2 workers per container
- 1 RPS per worker
- Total: 2 RPS (low load)
- Duration: 600 seconds (10 minutes)

Expected behavior:
- Container starts and begins sending requests
- CPU should be LOW (< 30%)
- No scaling should occur
- Alarms remain in OK state
- Watch terminal for "requests_sent" counter increasing

Monitor in CloudWatch:
- Open CloudWatch dashboard
- Watch CPU stay below 30%
- Watch RequestCount increase

Duration: Run for 2-3 minutes, then proceed to Phase 2

Stop command: Ctrl+C (in terminal)

================================================================================
STEP 6: RUN LOAD GENERATOR - PHASE 2 (MEDIUM LOAD)
================================================================================

After stopping Phase 1, increase load:

Command:
docker-compose up --scale agent1=3

This runs:
- 3 containers (3 agents in parallel)
- 2 workers per container = 6 total workers
- 1 RPS per worker = 6 total RPS
- Total: 6 RPS (medium load)
- Duration: 600 seconds (10 minutes)

Expected behavior:
- CPU should rise toward 50-70%
- Requests per second should increase
- Still below 80% threshold, so no scaling yet
- Alarms remain in OK state

Monitor in CloudWatch:
- Watch CPU rise to 50-70%
- Watch RequestCount increase significantly
- Watch for smooth request handling

Duration: Run for 3-5 minutes, then proceed to Phase 3

Stop command: Ctrl+C

================================================================================
STEP 7: RUN LOAD GENERATOR - PHASE 3 (HIGH LOAD - TRIGGER SCALING)
================================================================================

Now increase load to trigger scaling:

Command:
docker-compose up --scale agent1=5

This runs:
- 5 containers (5 agents in parallel)
- 2 workers per container = 10 total workers
- 1 RPS per worker = 10 total RPS
- Total: 10 RPS (high load)
- Duration: 600 seconds (10 minutes)

Expected behavior:
TIMELINE:
- 0-2 minutes: CPU rises toward 80%
- 2+ minutes: When CPU >= 80% for 2 consecutive minutes
  → cpu-high-alarm-80percent triggers
  → scale-out-policy executes
  → +1 instance added (ASG: 1 → 2)
  → New instance boots (takes 1-2 minutes)
  
- 4+ minutes: Second instance now running
  → Load distributed across 2 instances
  → CPU may drop slightly, then rise again as more requests come in
  
- 5+ minutes: If load sustained and CPU still >= 80%
  → Another scale-out triggered
  → +1 instance added (ASG: 2 → 3)
  → Third instance boots

- 6+ minutes: All 3 instances running
  → Load fully distributed
  → ASG at maximum capacity (3)
  → CPU may stabilize or continue high depending on load

Monitor in CloudWatch Dashboard:
- Watch CPU: starts rising toward 80%
- Watch RequestCount: increases to 10+ RPS
- Watch HealthyHostCount: goes from 1 → 2 → 3
- Watch Alarms: cpu-high-alarm-80percent transitions OK → IN_ALARM
- Watch ASG Activity: new instances launching

Check EC2 Instances:
- Go to EC2 > Instances
- Watch instance count increase from 1 → 2 → 3
- Note timestamps of each scaling event

IMPORTANT OBSERVATIONS TO RECORD:
1. Time when cpu-high-alarm-80percent triggered
2. Time when first instance was added (ASG: 1 → 2)
3. Time when second instance was added (ASG: 2 → 3)
4. CPU values at each point
5. Request count before and after scaling
6. How load was distributed across instances

Duration: Run for 10-15 minutes to observe full scaling

================================================================================
STEP 8: MONITOR SCALING EVENTS
================================================================================

While load is running, monitor these locations:

1. CloudWatch Dashboard:
   - Go to CloudWatch > Dashboards > D7078E-Lab-Dashboard
   - Watch CPU, RequestCount, HealthyHostCount in real-time
   - Take screenshots of each major event

2. ASG Activity:
   - Go to EC2 > Auto Scaling Groups > D7078E-MINI-PROJECT-GROUP35-ASG
   - Click "Activity" tab
   - Watch scaling events appear in real-time
   - Screenshot each scaling event

3. CloudWatch Alarms:
   - Go to CloudWatch > Alarms
   - Click on cpu-high-alarm-80percent
   - Watch state transition: OK → IN_ALARM
   - Screenshot when it triggers

4. EC2 Instances:
   - Go to EC2 > Instances
   - Filter by ASG
   - Watch instance count increase
   - Note instance IDs and launch times

5. Terminal Output:
   - Watch agent.py output showing requests being sent
   - Watch for any errors or dropped requests

================================================================================
STEP 9: OBSERVE SCALE-IN (WHEN LOAD DECREASES)
================================================================================

After Phase 3 completes or when you're ready to scale down:

Option A: Stop the load generator
Command: Ctrl+C (in terminal running docker-compose)

Option B: Scale down to fewer containers
Command: docker-compose up --scale agent1=1

Expected behavior:
- Load decreases
- CPU drops below 80%
- cpu-high-alarm-80percent transitions IN_ALARM → OK
- Wait 5+ minutes for cpu-low-alarm-30percent to trigger
- When CPU <= 30% for 5 consecutive minutes:
  → cpu-low-alarm-30percent triggers
  → scale-in-policy executes
  → -1 instance removed (ASG: 3 → 2)
  → Instance terminates gracefully

Monitor:
- Watch CPU drop over time
- Watch RequestCount decrease
- Watch HealthyHostCount decrease (3 → 2 → 1)
- Note timing of scale-in events

IMPORTANT: The scale-in may take 10+ minutes total because:
- Takes 5 minutes of low CPU to trigger the alarm
- Instance may take 1-2 minutes to terminate
- Total: 6-7 minutes from when load stops

================================================================================
STEP 10: CLEANUP AND DATA COLLECTION
================================================================================

After observing scaling:

1. Stop the load generator:
   Ctrl+C (in the docker-compose terminal)

2. Stop and remove containers:
   docker-compose down

3. Collect data:
   - Screenshot CloudWatch metrics
   - Export ASG activity log
   - Export CloudWatch alarms history
   - Save terminal output from load generator

4. Document observations:
   - When did scaling events occur?
   - How long did each instance take to boot?
   - What was the peak CPU?
   - What was peak RequestCount?
   - How many instances reached maximum (3)?
   - Did any instances fail health checks?

5. Calculate metrics:
   - Time from alarm trigger to instance available
   - Total requests served during test
   - Average RPS achieved
   - Peak RPS
   - Success rate

================================================================================
DELIVERABLES FOR TASK 4:
================================================================================

□ Screenshot: CloudWatch dashboard during low load (Phase 1)
□ Screenshot: CloudWatch dashboard during medium load (Phase 2)
□ Screenshot: CloudWatch dashboard during high load (Phase 3)
□ Screenshot: CloudWatch alarms transitioning to IN_ALARM
□ Screenshot: EC2 instances showing 1 → 2 → 3 instances
□ Screenshot: ASG Activity tab showing scaling events
□ Screenshot: Final CPU and RequestCount metrics
□ Document: Exact timestamps of each scaling event
□ Document: Peak CPU values at each phase
□ Document: RequestCount before/after each scaling
□ Terminal output: agent.py final statistics
□ Timeline: Event timeline from start to completion
□ Observations: What worked, what failed, lessons learned

================================================================================
TASK 4 SUMMARY
================================================================================

You will have demonstrated:
✓ Load generation with controlled traffic
✓ Auto-scaling triggered by CloudWatch alarms
✓ Scaling-out: 1 instance → 2 instances → 3 instances
✓ Load distribution across multiple instances
✓ CloudWatch alarm and metric monitoring
✓ Real-time observation of infrastructure scaling

Results should show:
✓ CPU rising from 0% → 80%+
✓ Alarms triggering at correct thresholds
✓ New instances launching on demand
✓ Load balanced across all instances
✓ No failed requests or health check failures

================================================================================
IMPORTANT NOTES & TIPS
================================================================================

TIPS FOR TASK 4:
- Start with LOW load first (verify connectivity works)
- Gradually RAMP UP load to avoid overwhelming instances
- Keep CloudWatch dashboard open and refreshing every 10 seconds
- Take screenshots FREQUENTLY during scaling events
- Document EXACT TIMES of each scaling event
- Monitor terminal output to ensure requests are actually being sent

LOAD PROGRESSION STRATEGY:
- Phase 1 (Low): 50-100 RPS → CPU 20-30% (no scaling)
- Phase 2 (Medium): 200-300 RPS → CPU 40-60% (no scaling yet)
- Phase 3 (High): 500-800 RPS → CPU 80%+ (SCALING TRIGGERS!)
- Phase 4 (Peak): 1000+ RPS → Demonstrates all 3 instances running

IMPORTANT TIMING:
- Scaling-out: ~2-3 minutes from alarm trigger to instance healthy
- Instance boot: ~1-2 minutes (depends on AMI and size)
- Scaling-in: ~10-15 minutes from load stopping (requires 5 minutes low CPU)

KEY METRICS TO MONITOR:
1. CPU Utilization
   - Low load: <30% ← No scaling
   - Medium load: 30-70% ← No scaling
   - High load: 80%+ ← SCALING TRIGGERS!

2. RequestCount
   - Should match your RPS calculation
   - Example: 10 workers × 5 RPS/worker = 50 RPS

3. HealthyHostCount
   - Starts: 1
   - After 1st scaling: 2
   - After 2nd scaling: 3 (maximum)

4. Response Times
   - Should stay consistent (under 100ms for / and /metrics)
   - /burn endpoint takes ~5 seconds (expected, CPU-intensive)

TROUBLESHOOTING:

Problem: "No scaling happening, stuck at 1 instance"
Solution: CPU not reaching 80%
  → Increase workers or RPS
  → Run multiple load scripts simultaneously
  → Verify alarm is correctly set to 80% (not 50%)

Problem: "Instances scale up but then scale down immediately"
Solution: Load drops after scaling
  → Increase total RPS to keep CPU high
  → Run load for longer duration
  → More workers needed

Problem: "Only reaches 2 instances, never gets to 3"
Solution: CPU drops below 80% after 2nd instance added
  → Load distributes too well across 2 instances
  → Need MORE load (5-10x more RPS)
  → Try running 3-5 load scripts simultaneously

Problem: "Requests failing or timeout errors"
Solution: Instance overloaded
  → Reduce workers/RPS
  → Verify instance can handle load
  → Check application logs on instance

SUCCESS CRITERIA:
✓ Phase 1: Low load, CPU stays below 30%, no scaling
✓ Phase 2: Medium load, CPU rises to 50-70%, still no scaling
✓ Phase 3: High load, CPU reaches 80%+, 1st scaling triggered
✓ 1st scaling: ASG scales 1 → 2 instances (within 2-3 minutes)
✓ 2nd scaling (if enough load): ASG scales 2 → 3 instances
✓ All 3 instances healthy in Target Group
✓ No failed requests, all instances responding
✓ Screenshots showing full scaling sequence

WHAT TO EXPECT IN GRAPHS:

CPU Utilization graph:
  - Starts: ~5%
  - Phase 1: Rises to 20%
  - Phase 2: Rises to 50-70%
  - Phase 3: Rises sharply to 80%+
  - After 1st scaling: May dip slightly (more CPU available), then rises again
  - After 2nd scaling: May dip again, load distribution across 3 instances
  - After 3rd instance: May stabilize lower (3x capacity)

RequestCount graph:
  - Stays at ~0 before load
  - Phase 1: Spikes to 50 RPS
  - Phase 2: Spikes to 200-300 RPS
  - Phase 3: Spikes to 500+ RPS
  - Stays high until load stops
  - Drops to 0 when load ends

HealthyHostCount graph:
  - Starts: 1
  - ~2 min mark: Rises to 2 (after 1st scaling)
  - ~5 min mark: Rises to 3 (after 2nd scaling)
  - Stays at 3 while load is high
  - ~15 min after load stops: Drops back to 2, then 1 (scale-in)

ASG Activity log:
  - "Launching 1 instances" (1st scaling)
  - "Successfully launched 1 instances" 
  - "Launching 1 instances" (2nd scaling)
  - "Successfully launched 1 instances"

DOCUMENTATION:
Record these exact times:
- 00:00 - Load test starts (Phase 1)
- 02:15 - CPU reaches 80%, alarm triggers
- 02:45 - 1st instance becomes healthy
- 03:00 - Phase 2 (increase load)
- 05:30 - 2nd scaling triggered
- 06:00 - 2nd instance becomes healthy
- 06:30 - Phase 3 (maximum load)
- 12:00 - Load test ends
- 17:00 - Scale-in starts (CPU drops to 30%)
- 22:00 - Instances start terminating
- 23:00 - Back to 1 instance

Calculate:
- Time from alarm trigger to instance healthy: ___ minutes
- Peak CPU percentage: ____%
- Peak RequestCount: ___ RPS
- How many instances reached: ___
- Total requests served: ___
- Average RPS achieved: ___

OPTIONAL: Run 3 load scripts simultaneously
```powershell
# PowerShell: Run multiple load generators at same time
# Window 1:
.\run_high_load.ps1

# Window 2:
.\run_max_load.ps1

# Window 3:
python agent.py --url http://ALB-DNS/ --workers 300 --rps 10 --duration 900
```

This 3x load almost guarantees reaching 3 instances!

================================================================================
NEXT TASK: Task 5 - Safe Failure Simulation
================================================================================

Note: Task 5 is OPTIONAL
- If 3 instances reached: Do Task 5 (failure simulation)
- If only 2 instances reached: Can skip to Task 6

===============================================================================

After completing Task 4, you will:
1. Trigger a controlled failure (FIS or SSM stress command)
2. Observe health checks and instance replacement
3. Watch recovery and failover behavior
4. Document all events

This completes the scaling and failure observation lab!

================================================================================

python agent.py --url http://D7078E-MINI-PROJECT-GROUP35-LB-8834940.eu-north-1.elb.amazonaws.com/ --workers 300 --rps 10 --duration 900