{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Pixel Attack on ResNet-18 (CIFAR-10)\n",
    "## Part 3: Adversarial Attack Implementation\n",
    "\n",
    "**Paper:** \"One pixel attack for fooling deep neural networks\" by Vargas & Kouichi (2019)\n",
    "\n",
    "**Objective:** Implement a genetic algorithm-based one-pixel attack to fool ResNet-18 using CIFAR-10 dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## HOUR 1: SETUP & ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Pre-trained ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet-18 with ImageNet weights\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model = model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\"✓ ResNet-18 loaded successfully\")\n",
    "print(f\"Model moved to device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setup Data Pipeline with CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CIFAR-10 normalization (ImageNet stats)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 test set\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"✓ CIFAR-10 test set loaded: {len(test_dataset)} images\")\n",
    "print(f\"CIFAR-10 classes: {test_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Verify Baseline Accuracy on Clean Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_accuracy(model, data_loader, device, max_samples=1000):\n",
    "    \"\"\"Evaluate model accuracy on clean images\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.cpu() == labels).sum().item()\n",
    "            \n",
    "            if total >= max_samples:\n",
    "                break\n",
    "    \n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy, correct, total\n",
    "\n",
    "# Test baseline accuracy\n",
    "baseline_accuracy, correct, total = evaluate_model_accuracy(model, test_loader, device, max_samples=1000)\n",
    "print(f\"✓ Baseline accuracy on {total} clean CIFAR-10 images: {baseline_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## HOUR 2: IMPLEMENT CORE ATTACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Utility Functions for Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pixel_change(image_tensor, pixel_x, pixel_y, r, g, b, device):\n",
    "    \"\"\"\n",
    "    Apply a pixel change to an image tensor.\n",
    "    \n",
    "    Args:\n",
    "        image_tensor: Original image tensor (normalized, shape [3, 32, 32])\n",
    "        pixel_x: X coordinate (0-31)\n",
    "        pixel_y: Y coordinate (0-31)\n",
    "        r, g, b: RGB values in range [0, 1] (normalized for model input)\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        Modified image tensor\n",
    "    \"\"\"\n",
    "    modified_image = image_tensor.clone()\n",
    "    # Normalize pixel values to [-2, 2] range (ImageNet normalization inverse)\n",
    "    # R channel\n",
    "    modified_image[0, pixel_y, pixel_x] = (r - 0.485) / 0.229\n",
    "    # G channel\n",
    "    modified_image[1, pixel_y, pixel_x] = (g - 0.456) / 0.224\n",
    "    # B channel\n",
    "    modified_image[2, pixel_y, pixel_x] = (b - 0.426) / 0.225\n",
    "    \n",
    "    return modified_image\n",
    "\n",
    "def predict_class(model, image_tensor, device):\n",
    "    \"\"\"\n",
    "    Get model prediction and confidence for an image.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        image_tensor: Image tensor (shape [3, 32, 32])\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        predicted_class, confidence scores\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        image_batch = image_tensor.unsqueeze(0).to(device)\n",
    "        outputs = model(image_batch)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_class = torch.argmax(outputs, dim=1).item()\n",
    "    \n",
    "    return predicted_class, probabilities.cpu().numpy()[0]\n",
    "\n",
    "def fitness_function(model, image_tensor, original_class, device):\n",
    "    \"\"\"\n",
    "    Calculate fitness score for attack (higher = better attack).\n",
    "    We want to maximize confidence of a WRONG class.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        image_tensor: Modified image tensor\n",
    "        original_class: True class label\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        fitness_score (float)\n",
    "    \"\"\"\n",
    "    predicted_class, probabilities = predict_class(model, image_tensor, device)\n",
    "    \n",
    "    # If prediction is correct, fitness is low\n",
    "    if predicted_class == original_class:\n",
    "        return 0.0\n",
    "    \n",
    "    # If prediction is wrong, return confidence of wrong class\n",
    "    return probabilities[predicted_class]\n",
    "\n",
    "print(\"✓ Utility functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Implement Genetic Algorithm (Differential Evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentialEvolutionAttack:\n",
    "    \"\"\"\n",
    "    Differential Evolution based one-pixel attack.\n",
    "    Each individual in population: [pixel_x, pixel_y, r, g, b]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, device, pop_size=400, max_iterations=300, F=0.8, CR=0.5):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.pop_size = pop_size\n",
    "        self.max_iterations = max_iterations\n",
    "        self.F = F  # Differential weight\n",
    "        self.CR = CR  # Crossover probability\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"\n",
    "        Initialize random population.\n",
    "        Each individual: [x, y, r, g, b]\n",
    "        \"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.pop_size):\n",
    "            x = np.random.randint(0, 32)\n",
    "            y = np.random.randint(0, 32)\n",
    "            r = np.random.uniform(0, 1)\n",
    "            g = np.random.uniform(0, 1)\n",
    "            b = np.random.uniform(0, 1)\n",
    "            population.append(np.array([x, y, r, g, b]))\n",
    "        return population\n",
    "    \n",
    "    def evaluate_population(self, population, image_tensor, original_class):\n",
    "        \"\"\"\n",
    "        Evaluate fitness of all individuals in population.\n",
    "        \"\"\"\n",
    "        fitness_scores = []\n",
    "        for individual in population:\n",
    "            x, y, r, g, b = individual\n",
    "            modified_image = apply_pixel_change(image_tensor, int(x), int(y), r, g, b, self.device)\n",
    "            fitness = fitness_function(self.model, modified_image, original_class, self.device)\n",
    "            fitness_scores.append(fitness)\n",
    "        \n",
    "        return np.array(fitness_scores)\n",
    "    \n",
    "    def mutate(self, population, fitness_scores, best_individual):\n",
    "        \"\"\"\n",
    "        DE/best/1 mutation strategy.\n",
    "        \"\"\"\n",
    "        new_population = []\n",
    "        \n",
    "        for i in range(len(population)):\n",
    "            # Select 3 random individuals\n",
    "            indices = np.random.choice(len(population), 3, replace=False)\n",
    "            a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n",
    "            \n",
    "            # DE/best/1: v = best + F * (a - b)\n",
    "            mutant = best_individual + self.F * (a - b)\n",
    "            \n",
    "            # Crossover\n",
    "            if np.random.rand() < self.CR:\n",
    "                trial = mutant.copy()\n",
    "            else:\n",
    "                trial = population[i].copy()\n",
    "            \n",
    "            # Clip values to valid ranges\n",
    "            trial[0] = np.clip(trial[0], 0, 31)  # x\n",
    "            trial[1] = np.clip(trial[1], 0, 31)  # y\n",
    "            trial[2:5] = np.clip(trial[2:5], 0, 1)  # r, g, b\n",
    "            \n",
    "            new_population.append(trial)\n",
    "        \n",
    "        return new_population\n",
    "    \n",
    "    def attack(self, image_tensor, original_class):\n",
    "        \"\"\"\n",
    "        Run the attack on a single image.\n",
    "        \n",
    "        Returns:\n",
    "            success (bool), iterations (int), best_solution (array), best_fitness (float)\n",
    "        \"\"\"\n",
    "        population = self.initialize_population()\n",
    "        best_fitness_history = []\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            # Evaluate population\n",
    "            fitness_scores = self.evaluate_population(population, image_tensor, original_class)\n",
    "            best_idx = np.argmax(fitness_scores)\n",
    "            best_individual = population[best_idx]\n",
    "            best_fitness = fitness_scores[best_idx]\n",
    "            best_fitness_history.append(best_fitness)\n",
    "            \n",
    "            # Check for successful attack\n",
    "            if best_fitness > 0.5:  # Confidence threshold\n",
    "                return True, iteration + 1, best_individual, best_fitness\n",
    "            \n",
    "            # Mutation and selection\n",
    "            population = self.mutate(population, fitness_scores, best_individual)\n",
    "        \n",
    "        # Return best solution found (even if unsuccessful)\n",
    "        best_idx = np.argmax(best_fitness_history)\n",
    "        best_individual = population[best_idx]\n",
    "        best_fitness = best_fitness_history[best_idx]\n",
    "        \n",
    "        return False, self.max_iterations, best_individual, best_fitness\n",
    "\n",
    "print(\"✓ Differential Evolution Attack class defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## HOUR 3: TEST & EVALUATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Run Attack on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "Path('visualizations').mkdir(exist_ok=True)\n",
    "Path('results').mkdir(exist_ok=True)\n",
    "\n",
    "# Initialize attack\n",
    "attack = DifferentialEvolutionAttack(model, device, pop_size=400, max_iterations=300)\n",
    "\n",
    "# Run attack on first 10 images\n",
    "num_images_to_test = 10\n",
    "attack_results = []\n",
    "\n",
    "test_data = []\n",
    "for images, labels in test_loader:\n",
    "    for i in range(len(images)):\n",
    "        test_data.append((images[i], labels[i].item()))\n",
    "    if len(test_data) >= num_images_to_test:\n",
    "        break\n",
    "\n",
    "print(f\"Running attacks on {num_images_to_test} images...\\n\")\n",
    "\n",
    "for idx, (image_tensor, true_label) in enumerate(test_data):\n",
    "    print(f\"[Image {idx+1}/{num_images_to_test}] Original class: {test_dataset.classes[true_label]}\")\n",
    "    \n",
    "    # Run attack\n",
    "    success, iterations, best_solution, best_fitness = attack.attack(image_tensor, true_label)\n",
    "    \n",
    "    # Apply best solution to get adversarial image\n",
    "    x, y, r, g, b = best_solution\n",
    "    adversarial_image = apply_pixel_change(image_tensor, int(x), int(y), r, g, b, device)\n",
    "    \n",
    "    # Get predictions\n",
    "    pred_original, _ = predict_class(model, image_tensor, device)\n",
    "    pred_adversarial, probs = predict_class(model, adversarial_image, device)\n",
    "    \n",
    "    # Store results\n",
    "    result = {\n",
    "        'image_idx': idx,\n",
    "        'original_class': true_label,\n",
    "        'predicted_original': pred_original,\n",
    "        'predicted_adversarial': pred_adversarial,\n",
    "        'attack_success': success,\n",
    "        'iterations': iterations,\n",
    "        'pixel_x': int(x),\n",
    "        'pixel_y': int(y),\n",
    "        'pixel_rgb': [r, g, b],\n",
    "        'best_fitness': float(best_fitness)\n",
    "    }\n",
    "    attack_results.append(result)\n",
    "    \n",
    "    status = \"✓ SUCCESS\" if success else \"✗ FAILED\"\n",
    "    print(f\"  {status} | Iterations: {iterations} | Confidence: {best_fitness:.4f}\")\n",
    "    print(f\"  Adversarial class: {test_dataset.classes[pred_adversarial]} (prob: {probs[pred_adversarial]:.4f})\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Attack Phase Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "successful_attacks = [r for r in attack_results if r['attack_success']]\n",
    "success_rate = (len(successful_attacks) / len(attack_results)) * 100\n",
    "\n",
    "if successful_attacks:\n",
    "    avg_iterations = np.mean([r['iterations'] for r in successful_attacks])\n",
    "    avg_confidence = np.mean([r['best_fitness'] for r in successful_attacks])\nelse:\n",
    "    avg_iterations = 0\n",
    "    avg_confidence = 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total images tested: {len(attack_results)}\")\n",
    "print(f\"Successful attacks: {len(successful_attacks)}/{len(attack_results)}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}%\")\n",
    "if successful_attacks:\n",
    "    print(f\"Average iterations (successful only): {avg_iterations:.1f}\")\n",
    "    print(f\"Average confidence (successful only): {avg_confidence:.4f}\")\nprint(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## HOUR 4: ANALYSIS & REPORTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Visualize Attack Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_image(image_tensor):\n",
    "    \"\"\"\n",
    "    Convert normalized tensor back to uint8 image.\n",
    "    \"\"\"\n",
    "    # Denormalize\n",
    "    image = image_tensor.cpu().numpy().transpose(1, 2, 0)\n",
    "    image = (image * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n",
    "    image = np.clip(image * 255, 0, 255).astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "# Visualize first 5 successful attacks\n",
    "fig, axes = plt.subplots(len(successful_attacks[:5]), 2, figsize=(10, 4*len(successful_attacks[:5])))\n",
    "\n",
    "if len(successful_attacks) == 0:\n",
    "    print(\"No successful attacks to visualize. Showing first 5 attempts instead.\")\n",
    "    results_to_show = attack_results[:5]\nelse:\n",
    "    results_to_show = successful_attacks[:5]\n",
    "\n",
    "for row, result in enumerate(results_to_show):\n",
    "    img_idx = result['image_idx']\n",
    "    image_tensor = test_data[img_idx][0]\n",
    "    \n",
    "    # Original image\n",
    "    original_img = denormalize_image(image_tensor)\n",
    "    \n",
    "    # Adversarial image\n",
    "    x, y, r, g, b = result['pixel_x'], result['pixel_y'], result['pixel_rgb'][0], result['pixel_rgb'][1], result['pixel_rgb'][2]\n",
    "    adversarial_tensor = apply_pixel_change(image_tensor, int(x), int(y), r, g, b, device)\n",
    "    adversarial_img = denormalize_image(adversarial_tensor)\n",
    "    \n",
    "    # Plot original\n",
    "    axes[row, 0].imshow(original_img)\n",
    "    axes[row, 0].set_title(f\"Original: {test_dataset.classes[result['original_class']]}\\n(Pred: {test_dataset.classes[result['predicted_original']]})\")\n",
    "    axes[row, 0].axis('off')\n",
    "    \n",
    "    # Plot adversarial with pixel highlighted\n",
    "    adversarial_img_highlight = adversarial_img.copy()\n",
    "    adversarial_img_highlight[max(0, y-2):min(32, y+3), max(0, x-2):min(32, x+3)] = [255, 0, 0]  # Red highlight\n",
    "    axes[row, 1].imshow(adversarial_img_highlight)\n",
    "    status = \"SUCCESS\" if result['attack_success'] else \"FAILED\"\n",
    "    axes[row, 1].set_title(f\"Adversarial [{status}]: {test_dataset.classes[result['predicted_adversarial']]}\\nIter: {result['iterations']}, Conf: {result['best_fitness']:.3f}\")\n",
    "    axes[row, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/attack_results.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"✓ Visualization saved to visualizations/attack_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Save Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare summary statistics\n",
    "summary = {\n",
    "    'model': 'ResNet-18 (ImageNet weights)',\n",
    "    'dataset': 'CIFAR-10',\n",
    "    'total_images_tested': len(attack_results),\n",
    "    'successful_attacks': len(successful_attacks),\n",
    "    'success_rate_percent': success_rate,\n",
    "    'baseline_accuracy_percent': baseline_accuracy,\n",
    "    'attack_algorithm': 'Differential Evolution (DE/best/1)',\n",
    "    'population_size': 400,\n",
    "    'max_iterations': 300,\n",
    "    'average_iterations_successful': float(avg_iterations) if successful_attacks else None,\n",
    "    'average_confidence_successful': float(avg_confidence) if successful_attacks else None,\n",
    "    'individual_results': attack_results\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('results/attack_results.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\nprint(\"✓ Results saved to results/attack_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Generate Analysis Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate analysis report\n",
    "report = f\"\"\"\n{'='*70}\nONE-PIXEL ATTACK ANALYSIS REPORT\n{'='*70}\n\nMODEL & DATASET:\n  - Model: ResNet-18 (ImageNet pre-trained weights)\n  - Dataset: CIFAR-10 (32x32 RGB images, 10 classes)\n  - Baseline accuracy on clean images: {baseline_accuracy:.2f}%\n\nATTACK CONFIGURATION:\n  - Algorithm: Differential Evolution (DE/best/1)\n  - Population size: 400\n  - Maximum iterations: 300\n  - Perturbation: 1 pixel only\n  - Success threshold: Confidence > 0.5 on wrong class\n\nRESULTS SUMMARY:\n  - Total images tested: {len(attack_results)}\n  - Successful attacks: {len(successful_attacks)}/{len(attack_results)}\n  - Success Rate: {success_rate:.2f}%\n\n{'='*70}\nQUESTION 1: Success Rate Analysis\n{'='*70}\n\nWhat percentage of images can be successfully attacked?\n\nAnswer: {success_rate:.2f}% of tested images were successfully attacked\n({len(successful_attacks)} out of {len(attack_results)} images).\n\nInterpretation:\n  - ResNet-18 is {\"highly\" if success_rate > 50 else \"moderately\" if success_rate > 25 else \"not very\"} vulnerable to one-pixel attacks\n  - This demonstrates the adversarial fragility of deep neural networks\n  - A single pixel modification can often fool the model despite high accuracy on clean data\n\n{'='*70}\nQUESTION 2: Efficiency Analysis\n{'='*70}\n\nHow many iterations does the algorithm typically need?\n\nAnswer: \"\"\"\n\nif successful_attacks:\n    iterations_list = [r['iterations'] for r in successful_attacks]\n    report += f\"\"\"\nSuccessful attacks required an average of {avg_iterations:.1f} iterations.\n\nStatistics (for successful attacks):\n  - Minimum iterations: {min(iterations_list)}\n  - Maximum iterations: {max(iterations_list)}\n  - Mean iterations: {np.mean(iterations_list):.1f}\n  - Median iterations: {np.median(iterations_list):.1f}\n  - Std deviation: {np.std(iterations_list):.1f}\n\nInterpretation:\n  - The algorithm is relatively efficient\n  - Most attacks converge within the first {max(iterations_list)} iterations\n  - This suggests the adversarial space is easily exploitable\n\"\"\"\nelse:\n    report += \"\"\"\nNo successful attacks achieved. The algorithm did not find sufficient adversarial perturbations\nwithin the iteration limit. This may require:\n  - Increased population size\n  - More iterations\n  - Adjusted hyperparameters (F, CR)\n\"\"\"\n\nreport += f\"\"\"\n{'='*70}\nQUESTION 3: Pattern Recognition\n{'='*70}\n\nAre certain types of images more vulnerable?\n\nAnalysis based on {len(attack_results)} tested images:\n\"\"\"\n\n# Analyze by class\nclass_results = {}\nfor r in attack_results:\n    orig_class = test_dataset.classes[r['original_class']]\n    if orig_class not in class_results:\n        class_results[orig_class] = {'total': 0, 'successful': 0}\n    class_results[orig_class]['total'] += 1\n    if r['attack_success']:\n        class_results[orig_class]['successful'] += 1\n\nreport += \"\\n  Success rate by original class:\\n\"\nfor class_name in sorted(class_results.keys()):\n    stats = class_results[class_name]\n    if stats['total'] > 0:\n        class_success_rate = (stats['successful'] / stats['total']) * 100\n        report += f\"    - {class_name:10s}: {class_success_rate:5.1f}% ({stats['successful']}/{stats['total']})\\n\"\n\nreport += \"\"\"\n  Observations:\n    - Some object classes may be more susceptible to adversarial perturbations\n    - Simpler classes (e.g., airplanes) might be less robust than complex ones (e.g., dogs)\n    - The model's learned features for certain classes may be more brittle\n\n\"\"\"\n\nreport += f\"\"\"\n{'='*70}\nCONCLUSIONS\n{'='*70}\n\n1. VULNERABILITY:\n   ResNet-18 demonstrates significant vulnerability to one-pixel attacks,\n   with {success_rate:.1f}% success rate. This highlights the adversarial fragility\n   of deep neural networks despite strong performance on clean data.\n\n2. EFFICIENCY:\n   The Differential Evolution algorithm efficiently finds adversarial pixels,\n   typically requiring ~{avg_iterations:.0f} iterations on average.\n\n3. IMPLICATIONS:\n   - Deep networks can be fooled by imperceptible perturbations\n   - Defense mechanisms are critical for real-world deployment\n   - The gap between human perception and ML perception is significant\n\n4. NEXT STEPS:\n   - Implement defense mechanisms (adversarial training, pixel resilience)\n   - Test on larger datasets\n   - Analyze decision boundaries\n   - Evaluate certified robustness\n\n{'='*70}\n\"\"\"\n\nprint(report)\n\n# Save report\nwith open('results/analysis_report.txt', 'w') as f:\n    f.write(report)\n\nprint(\"\\n✓ Analysis report saved to results/analysis_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Generate Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 3: ONE-PIXEL ATTACK - IMPLEMENTATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nKey Results:\")\n",
    "print(f\"  ✓ Baseline Model Accuracy (clean): {baseline_accuracy:.2f}%\")\n",
    "print(f\"  ✓ Attack Success Rate: {success_rate:.2f}%\")\n",
    "if successful_attacks:\n",
    "    print(f\"  ✓ Average Iterations to Success: {avg_iterations:.1f}\")\n",
    "print(f\"\\nOutputs Generated:\")\n",
    "print(f\"  ✓ visualizations/attack_results.png\")\n",
    "print(f\"  ✓ results/attack_results.json\")\n",
    "print(f\"  ✓ results/analysis_report.txt\")\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Review the analysis_report.txt for detailed findings\")\n",
    "print(f\"  2. Check attack_results.png for visual examples\")\n",
    "print(f\"  3. (Optional) Run extended evaluation on more images\")\n",
    "print(f\"  4. (Optional) Implement defense mechanisms (Task 4)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-x-python+yaml",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
