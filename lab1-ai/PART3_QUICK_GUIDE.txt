================================================================================
PART 3: ONE-PIXEL ATTACK - 4 HOUR QUICK IMPLEMENTATION GUIDE
================================================================================

OVERVIEW:
Implement a one-pixel attack on ResNet-18 using CIFAR-10 dataset.
Attack changes 1 pixel to fool the neural network.
Paper: "One pixel attack for fooling deep neural networks" (Vargas & Kouichi 2019)

================================================================================
TIMELINE BREAKDOWN (4 hours)
================================================================================

HOUR 1: SETUP & ENVIRONMENT (60 min)
-----------------------------------
[0-15 min] Install dependencies:
  - pip install torch torchvision pytorch-lightning
  - pip install numpy matplotlib opencv-python
  - Ensure ResNet-18 and CIFAR-10 are downloaded/cached

[15-30 min] Load pre-trained ResNet-18:
  - Use torchvision.models.resnet18(pretrained=True)
  - Load CIFAR-10 test set
  - Verify model accuracy on clean images (baseline)

[30-60 min] Setup data pipeline:
  - Create image loader for single images
  - Define normalization (ImageNet stats: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
  - Create function to apply pixel changes and forward pass

HOUR 2: IMPLEMENT CORE ATTACK (60 min)
--------------------------------------
[60-90 min] Implement Genetic Algorithm (DE - Differential Evolution):
  - Population size: 400 pixels max (try this first)
  - Mutation strategy: DE/best/1
  - Crossover rate: 0.5
  - For each generation:
    * Mutate population
    * Evaluate fitness
    * Select best
    * Stop if successful attack or max iterations (300) reached

[90-120 min] Key Functions:
  1. apply_pixel_change(image, pixel_coords, RGB_values):
     - pixel_coords: (x, y)
     - RGB_values: (R, G, B) in [0-255]
     - Return modified image tensor normalized

  2. fitness_function(modified_image, true_class):
     - Forward pass through model
     - Return: confidence of wrong class (maximize this)
     - Penalize if still correct class

  3. mutation_strategy(population, best_individual):
     - Create new candidates from differential evolution
     - Clip values to valid ranges

HOUR 3: TEST & EVALUATE (60 min)
--------------------------------
[120-150 min] Run attack on test images:
  - Start with 10 random images from CIFAR-10 test set
  - For each image:
    * Run attack algorithm
    * Record: iterations needed, attack success (Y/N)
    * Save original + attacked image for visualization

[150-180 min] Analyze results:
  - Success Rate: (successful attacks / total) × 100%
  - Efficiency: average iterations until success
  - Perturbation magnitude: max pixel change needed

HOUR 4: ANALYSIS & REPORTING (60 min)
-------------------------------------
[180-210 min] Run extended evaluation:
  - Try 50-100 images if time permits (adjust evaluation scope)
  - Identify patterns: color vs B&W, simple vs complex images
  - Document vulnerabilities

[210-240 min] Prepare results:
  - Create visualization: original vs attacked images + heatmap of pixel change
  - Tabulate success rates
  - Write brief findings (3-5 sentences per question)
  - Questions to answer:
    1. Success rate %?
    2. Average iterations?
    3. Pattern observations (difficult/easy targets)?

================================================================================
IMPLEMENTATION TIPS
================================================================================

GENETIC ALGORITHM PSEUDOCODE:
```
for each test_image:
  population = random_population(size=400)  # Each: [x, y, r, g, b]
  
  for generation in range(max_iterations=300):
    fitness_scores = [evaluate(pop_member) for pop_member in population]
    
    if any(attack_successful):
      return success
    
    # Selection + Mutation
    best = population[argmax(fitness_scores)]
    new_pop = apply_DE_mutation(population, best)
    population = new_pop

return failure_after_300_iterations
```

CRITICAL CONSTRAINTS:
- Pixel coords: 0 <= x < 32, 0 <= y < 32 (CIFAR-10 is 32×32)
- RGB values: 0 <= R, G, B <= 255 (convert to 0-1 for model)
- Attack success: model predicts WRONG class with high confidence
- Efficiency metric: fewer iterations = better

DEBUGGING CHECKLIST:
✓ Model loads and predicts correctly on clean images
✓ Pixel modification function works (visualize one modified image)
✓ Fitness calculation correctly identifies wrong predictions
✓ DE mutation generates valid candidates
✓ Population size balanced: 400 is aggressive; start here or reduce to 300
✓ Check iteration limit: 300 should be reasonable (can reduce to 100 if slow)

POTENTIAL SPEEDUPS:
- Use GPU: model.to('cuda') if available
- Batch processing: evaluate multiple candidates per iteration
- Early stopping: stop after ~10 successful attacks for efficiency analysis
- Reduce population to 200-300 if time-constrained

================================================================================
EXPECTED RESULTS
================================================================================

Baseline ResNet-18 on CIFAR-10 clean images: ~95% accuracy
After one-pixel attack success rate: 50-70% (varies by algorithm tuning)
Average iterations: 50-150 (depending on DE parameters)

================================================================================
FILES TO CREATE
================================================================================

1. one_pixel_attack.py - Main implementation
2. results_summary.txt - Results and analysis answers
3. visualizations/ - Folder with before/after attack images

OUTPUT TEMPLATE FOR RESULTS:
---
Success Rate Analysis: X% of images successfully attacked
Efficiency Analysis: Average Y iterations needed
Pattern Recognition: [Observations about image types]
---

================================================================================
GO! You've got this. Focus on getting attack + evaluation working first.
Analysis can be quick once data is collected.
================================================================================
