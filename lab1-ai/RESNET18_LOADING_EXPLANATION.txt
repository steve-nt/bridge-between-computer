================================================================================
STEP 2: LOAD PRE-TRAINED RESNET-18 - DETAILED EXPLANATION
================================================================================

OUTPUT RECEIVED:
  ✓ ResNet-18 loaded successfully
  Model moved to device: cpu

CODE:
  model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
  model = model.to(device)
  model.eval()
  print("✓ ResNet-18 loaded successfully")
  print(f"Model moved to device: {device}")

================================================================================
LINE-BY-LINE BREAKDOWN
================================================================================

LINE 1: model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
================================================================================

WHAT IT DOES:
  Creates a ResNet-18 neural network with pre-trained ImageNet weights

EXPLANATION:

  models.resnet18(...)
  ├─ Function from torchvision.models
  ├─ Creates ResNet-18 architecture
  └─ ResNet-18 = 18-layer Residual Network
     - 18 convolutional layers
     - ~11 million parameters
     - Lightweight (good for inference)

  weights=models.ResNet18_Weights.IMAGENET1K_V1
  ├─ Loads pre-trained weights from ImageNet dataset
  ├─ ImageNet: 1.2M training images, 1000 classes
  ├─ Model already learned features from ImageNet
  └─ Why ImageNet weights?
     - ResNet trained on ImageNet generalizes well to CIFAR-10
     - Transfer learning: Reuse learned features
     - Better performance than random initialization
     - Faster convergence/inference

ANALOGY:
  Without pre-trained weights:
    = Untrained person trying to identify animals
    = Zero knowledge, must learn from scratch
  
  With pre-trained weights:
    = Expert zoologist transferred to new task
    = Already knows general animal features
    = Faster and better at new task (CIFAR-10)

WHAT YOU GET:
  model = ResNet-18 neural network object ready to use
  
  Model architecture looks like:
    Input (3 channels: RGB)
      ↓
    Conv Layer 1 → Conv Layer 2 → ... → Conv Layer 18
      ↓
    Global Average Pooling
      ↓
    Fully Connected Layer (1000 classes)
      ↓
    Output Probabilities

PARAMETERS:
  Total: ~11.7 million learned weights
  Loaded from: PyTorch model zoo (cached locally)

================================================================================
LINE 2: model = model.to(device)
================================================================================

WHAT IT DOES:
  Moves the model to GPU or CPU

DETAILED EXPLANATION:

  model.to(device)
  ├─ Method that transfers model to specified device
  ├─ device = "cpu" or "cuda" (GPU)
  └─ In your case: device = "cpu"

WHY MOVE THE MODEL?

  GPU (CUDA):
    ✓ Much faster computation (~100x faster)
    ✓ Can process hundreds of images simultaneously
    ✓ For 10 images: ~1-2 seconds
    ✗ Limited VRAM (video memory)
    ✗ Not always available

  CPU:
    ✓ Always available
    ✓ Works anywhere (laptops, servers)
    ✗ Much slower (~100x slower than GPU)
    ✗ Single-threaded by default
    ✗ For 10 images: ~30-60 seconds

YOUR SITUATION:
  ⚠️ Running on CPU (device: cpu)
  Possible reasons:
    1. No GPU detected (CUDA not initialized)
    2. GPU memory issue
    3. CUDA drivers not configured properly
  
  Performance impact:
    × 10 images will take ~30-60 seconds instead of 1-2 seconds
    × Genetic algorithm will be slower
    × Test will still work, just slower

WHAT HAPPENS:

  Before: model.to(device)
    ResNet parameters stored in RAM (CPU memory)
    ├─ Weights: ~46 MB of RAM
    └─ Computations: CPU handles all calculations
  
  After: model.to(device)
    Same - everything stays on CPU
    └─ No change in this case since device="cpu"
  
  If device was "cuda":
    ResNet parameters transferred to GPU VRAM
    ├─ Weights: ~46 MB of VRAM
    └─ Computations: GPU handles all calculations (100x faster)

IMPORTANCE:
  ✅ NECESSARY: Without this line, code will crash with:
     "Expected all tensors to be on the same device"
  
  Why? When you feed images to model:
    ✓ Images on CPU, model on GPU → ERROR
    ✓ Images on GPU, model on CPU → ERROR
    ✓ Both on same device → Works ✓

================================================================================
LINE 3: model.eval()
================================================================================

WHAT IT DOES:
  Sets model to evaluation mode (inference mode)

DETAILED EXPLANATION:

  model.eval()
  ├─ Disables training-specific behaviors
  ├─ Locks model in "evaluation" state
  └─ No more weight updates

WHY IS THIS IMPORTANT?

  Two modes in neural networks:

  TRAINING MODE (model.train()):
    ├─ Enabled: Batch Normalization layers
    ├─ Enabled: Dropout (randomly disable neurons)
    ├─ Purpose: Prevent overfitting during training
    ├─ Behavior: Non-deterministic (different results each run)
    └─ Used when: Learning weights
  
  EVALUATION MODE (model.eval()):
    ├─ Disabled: Batch Normalization (uses running stats)
    ├─ Disabled: Dropout
    ├─ Purpose: Consistent, deterministic predictions
    ├─ Behavior: Same results for same input
    └─ Used when: Making predictions (inference)

PRACTICAL DIFFERENCE:

  Batch Normalization:
    Training: Uses statistics from current batch
    Eval: Uses running statistics (computed during training)
  
  Dropout:
    Training: Randomly disables 50% of neurons (example)
    Eval: All neurons active
  
  Result:
    Training: ~75% accuracy (with dropout), ~92% accuracy (without)
    Eval: ~92% accuracy (consistent)

IN YOUR CASE:

  You're not training, you're attacking
  → Must use model.eval() ✓
  → Ensures consistent baseline accuracy
  → Ensures consistent attack behavior

WHAT HAPPENS IF YOU FORGET model.eval()?

  ✗ Problem: Results vary each run (dropout random)
  ✗ Problem: Different accuracy measurements
  ✗ Result: Hard to reproduce, hard to debug

================================================================================
LINE 4-5: Print Statements
================================================================================

print("✓ ResNet-18 loaded successfully")
print(f"Model moved to device: {device}")

WHAT IT DOES:
  Prints confirmation messages to terminal

WHAT YOU SEE:
  ✓ ResNet-18 loaded successfully
  Model moved to device: cpu

IMPORTANCE:
  ⚠️ Optional but helpful
  ✓ Confirms model loading worked
  ✓ Shows which device is active
  ✓ Good for debugging

INTERPRETATION:

  "✓ ResNet-18 loaded successfully"
  → Model weights loaded correctly
  → No errors during initialization
  → Ready for use ✓

  "Model moved to device: cpu"
  → Model is on CPU (not GPU)
  → Slower inference speed expected
  → All computations will use CPU

================================================================================
YOUR OUTPUT INTERPRETATION
================================================================================

OUTPUT: Model moved to device: cpu

WHAT THIS MEANS:
  GPU is NOT being used
  All computations will run on CPU
  Attack will be slower than expected

POSSIBLE REASONS:
  1. CUDA not properly installed
  2. No NVIDIA GPU available
  3. GPU driver issues
  4. torch.cuda.is_available() returned False

CHECK IF GPU AVAILABLE:
  Run in Jupyter:
    import torch
    print(torch.cuda.is_available())
    print(torch.cuda.get_device_name(0))
  
  If False → GPU not available
  If True + Error → Driver issue

PERFORMANCE IMPACT:
  CPU: ~30-100 seconds for 10 images
  GPU: ~1-3 seconds for 10 images
  
  Impact: Your attack will take longer but still work ✓

WHAT TO DO:
  Option 1: Continue with CPU (works but slower)
  Option 2: Debug GPU setup (optional)
  Recommendation: Continue with CPU for now ✓

================================================================================
COMPLETE UNDERSTANDING SUMMARY
================================================================================

What the code does:
  1. Load ResNet-18 pre-trained on ImageNet
     → Gets a smart model with learned features
  
  2. Move model to device (CPU)
     → Prepares model for inference
  
  3. Set to evaluation mode
     → Ensures consistent, deterministic predictions
  
  4. Print confirmation
     → Verify everything worked

Result:
  ✓ Model ready for adversarial attacks
  ✓ Model set to inference mode (not training)
  ✓ Model on CPU (slower but functional)
  ✓ Ready for CIFAR-10 images

================================================================================
NEXT STEP
================================================================================

Continue running Cell 3:
  "Setup Data Pipeline with CIFAR-10"

This will:
  1. Download CIFAR-10 dataset (~170 MB first time)
  2. Apply image normalization (ImageNet stats)
  3. Create data loader for batch processing

After that: Run Cell 4 to check baseline accuracy

================================================================================
