================================================================================
D7078E Lab 3: Multi-Tier Isolation - DETAILED IMPLEMENTATION GUIDE
================================================================================
Deadline: December 10, 2025
This guide provides step-by-step instructions for implementing the lab with 
screenshot requirements for each task.

================================================================================
OVERVIEW
================================================================================
You will create a secure multi-tier AWS infrastructure with:
- 3 EC2 instances (Web, Database, Storage)
- 3 Security Groups (strict isolation rules)
- S3 bucket for storage
- API Gateway for controlled access
- IAM roles for least privilege
- CloudWatch for monitoring
- CloudTrail for logging

================================================================================
PREREQUISITES - TAKE SCREENSHOT
================================================================================
Before starting, verify you have:
□ AWS Management Console access
□ Valid AWS account with adequate credits
□ Your @stud.ltu.se email
□ A terminal/SSH client for EC2 access
□ Administrator IP address noted (for SSH access to DB server)

SCREENSHOT 1: Take a screenshot of your AWS Console home page showing you are 
logged in with your account visible.

================================================================================
TASK 1: CREATE 3 EC2 INSTANCES
================================================================================

STEP 1.1 - CREATE FIRST EC2 INSTANCE (WEB SERVER)
-----------
1. Log in to AWS Management Console
2. Navigate to EC2 → Instances → "Launch instances"
3. Configure Instance Details:
   Name: "WEB-SERVER"
   AMI: Select Ubuntu Server 22.04 LTS (or latest)
   Instance Type: t2.micro (free tier)
   Number of instances: 1

4. Network Settings:
   VPC: Default VPC
   Subnet: Default subnet
   Auto-assign public IP: Enable
   Security Group: Create NEW → Name: "SG-WEB"

5. Storage Configuration:
   Size: 8 GB (default)

6. Key Pair:
   Create new key pair: Name it "lab3-key"
   Format: .pem
   Download the key pair immediately and save securely

7. Click "Launch instances"

SCREENSHOT 1.1: Show the "Launch Instance" confirmation page with instance 
details visible, including the instance name "WEB-SERVER" and the instance ID.

Wait 2-3 minutes for the instance to reach "running" state.

SCREENSHOT 1.2: Show the Instances dashboard with WEB-SERVER running, displaying:
- Instance ID
- Public IP address
- Private IP address
- Instance State: running


STEP 1.2 - CREATE SECOND EC2 INSTANCE (DATABASE SERVER)
-----------
1. Go to EC2 → Instances → "Launch instances"
2. Configure Instance Details:
   Name: "DB-SERVER"
   AMI: Ubuntu Server 22.04 LTS
   Instance Type: t2.micro
   Number of instances: 1

3. Network Settings:
   VPC: Default VPC
   Subnet: Default subnet
   Auto-assign public IP: Enable
   Security Group: Create NEW → Name: "SG-DB"

4. Storage: 8 GB (default)

5. Key Pair: Select existing "lab3-key"

6. Click "Launch instances"

SCREENSHOT 1.3: Show DB-SERVER instance running with:
- Instance name visible
- Instance ID
- Private IP and Public IP addresses


STEP 1.3 - CREATE THIRD EC2 INSTANCE (STORAGE SERVER)
-----------
1. Go to EC2 → Instances → "Launch instances"
2. Configure Instance Details:
   Name: "STORAGE-SERVER"
   AMI: Ubuntu Server 22.04 LTS
   Instance Type: t2.micro
   Number of instances: 1

3. Network Settings:
   VPC: Default VPC
   Subnet: Default subnet
   Auto-assign public IP: Enable
   Security Group: Create NEW → Name: "SG-STORAGE"

4. Storage: 8 GB (default)

5. Key Pair: Select existing "lab3-key"

6. Click "Launch instances"

SCREENSHOT 1.4: Show all 3 instances (WEB-SERVER, DB-SERVER, STORAGE-SERVER) 
in the Instances dashboard, all in "running" state with their respective IPs.

Note down the following information for later use:
┌─────────────────────────────────────────────────────────────────┐
│ INSTANCE INFORMATION (Update as you create instances)           │
├─────────────────────────────────────────────────────────────────┤
│ WEB-SERVER:                                                     │
│   Instance ID: ________________________                          │
│   Private IP: ________________________                           │
│   Public IP: ________________________                            │
│                                                                 │
│ DB-SERVER:                                                      │
│   Instance ID: ________________________                          │
│   Private IP: ________________________                           │
│   Public IP: ________________________                            │
│   Admin Access IP (Your IP): ________________________             │
│                                                                 │
│ STORAGE-SERVER:                                                 │
│   Instance ID: ________________________                          │
│   Private IP: ________________________                           │
│   Public IP: ________________________                            │
└─────────────────────────────────────────────────────────────────┘

================================================================================
TASK 2: INSTALL REQUIRED SOFTWARE ON INSTANCES
================================================================================

STEP 2.1 - CONNECT TO WEB-SERVER VIA SSH
-----------
1. Open your terminal/command prompt
2. Change permissions on your key pair:
   chmod 400 lab3-key.pem

3. Connect to WEB-SERVER:
   ssh -i lab3-key.pem ubuntu@<WEB-SERVER-PUBLIC-IP>

4. When prompted, type "yes" to accept the host key

SCREENSHOT 2.1: Show terminal with successful SSH connection to WEB-SERVER.
Verify you see: ubuntu@ip-<private-ip>:~$

STEP 2.2 - INSTALL WEB SERVER (NGINX) ON WEB-SERVER
-----------
1. Update package manager:
   sudo apt update

2. Install Nginx:
   sudo apt install -y nginx

3. Start Nginx:
   sudo systemctl start nginx
   sudo systemctl enable nginx

4. Create a test HTML file:
   sudo nano /var/www/html/index.html

5. Paste the following content:
   <!DOCTYPE html>
   <html>
   <head>
       <title>Lab 3 - Web Server</title>
   </head>
   <body>
       <h1>Lab 3 Multi-Tier Isolation</h1>
       <p>This is the Web Application Server (EC2-1)</p>
       <p>Hostname: <?php echo gethostname(); ?></p>
   </body>
   </html>

6. Save and exit (Ctrl+O, Enter, Ctrl+X)

7. Verify Nginx is running:
   sudo systemctl status nginx

SCREENSHOT 2.2: Show terminal output of the Nginx status being "active (running)"

8. Exit SSH:
   exit

STEP 2.3 - CONNECT TO DB-SERVER VIA SSH
-----------
1. In terminal, connect:
   ssh -i lab3-key.pem ubuntu@<DB-SERVER-PUBLIC-IP>

SCREENSHOT 2.3: Show successful SSH connection to DB-SERVER

STEP 2.4 - INSTALL DATABASE SERVER (MYSQL) ON DB-SERVER
-----------
1. Update package manager:
   sudo apt update

2. Install MySQL Server:
   sudo apt install -y mysql-server

3. Start MySQL:
   sudo systemctl start mysql
   sudo systemctl enable mysql

4. Secure MySQL installation:
   sudo mysql_secure_installation
   
   When prompted:
   - Validate password plugin: n (skip)
   - Remove anonymous users: y
   - Disable remote root login: y
   - Remove test database: y
   - Reload privilege tables: y

5. Connect to MySQL to verify:
   sudo mysql -u root

6. Create a test database:
   CREATE DATABASE lab3_db;
   CREATE TABLE lab3_db.test_table (id INT, name VARCHAR(100));
   INSERT INTO lab3_db.test_table VALUES (1, 'Lab3 Test');
   SELECT * FROM lab3_db.test_table;

7. Exit MySQL:
   exit

8. Verify MySQL is running:
   sudo systemctl status mysql

SCREENSHOT 2.4: Show MySQL connection and the test table creation/query output

9. Exit SSH:
   exit

STEP 2.5 - CONNECT TO STORAGE-SERVER VIA SSH
-----------
1. In terminal, connect:
   ssh -i lab3-key.pem ubuntu@<STORAGE-SERVER-PUBLIC-IP>

SCREENSHOT 2.5: Show successful SSH connection to STORAGE-SERVER

STEP 2.6 - INSTALL AWS CLI AND PYTHON ON STORAGE-SERVER
-----------
1. Update package manager:
   sudo apt update

2. Install AWS CLI:
   sudo apt install -y awscli

3. Install Python3 and pip:
   sudo apt install -y python3 python3-pip

4. Verify installations:
   aws --version
   python3 --version
   pip3 --version

SCREENSHOT 2.6: Show output of all three version commands confirming installations

5. Configure AWS CLI (use your AWS credentials):
   aws configure
   
   When prompted:
   - AWS Access Key ID: [Your access key]
   - AWS Secret Access Key: [Your secret key]
   - Default region name: [Choose your region, e.g., us-east-1]
   - Default output format: json

6. Test AWS CLI by listing S3 buckets:
   aws s3 ls
   (This will be empty initially)

SCREENSHOT 2.7: Show output of "aws s3 ls" command

7. Exit SSH:
   exit

================================================================================
TASK 3: CONFIGURE SECURITY GROUPS (STRICT ISOLATION)
================================================================================

STEP 3.1 - CONFIGURE SG-WEB SECURITY GROUP
-----------
1. In AWS Console, go to EC2 → Security Groups
2. Find and click "SG-WEB"
3. Click "Edit inbound rules"

Delete any existing rules, then add:

RULE 1 (HTTPS from Internet):
- Type: HTTPS
- Protocol: TCP
- Port: 443
- Source: 0.0.0.0/0
- Description: "HTTPS from anywhere - public web access"

RULE 2 (Optional SSH for admin):
- Type: SSH
- Protocol: TCP
- Port: 22
- Source: <YOUR-ADMIN-IP>/32 (e.g., 203.0.113.55/32)
- Description: "SSH from admin only"

DO NOT ADD:
❌ Any rules allowing traffic from SG-DB
❌ Any rules allowing traffic from SG-STORAGE
❌ MySQL port 3306
❌ Any EC2-to-EC2 communication

4. Click "Save rules"

SCREENSHOT 3.1: Show SG-WEB inbound rules clearly displaying:
- HTTPS (443) from 0.0.0.0/0
- Optional SSH rule (if added)
- Note: No rules for database or storage access

5. Click "Edit outbound rules" to review:

For outbound, you can restrict to:
- HTTPS (443) to 0.0.0.0/0 (for API Gateway calls)
- DNS (53) to 0.0.0.0/0 (for domain resolution)
- No rules to other EC2 instances

SCREENSHOT 3.2: Show SG-WEB outbound rules


STEP 3.2 - CONFIGURE SG-DB SECURITY GROUP
-----------
1. Find and click "SG-DB"
2. Click "Edit inbound rules"

Delete any existing rules, then add:

RULE 1 (SSH only from admin):
- Type: SSH
- Protocol: TCP
- Port: 22
- Source: <YOUR-ADMIN-IP>/32 (e.g., 203.0.113.55/32)
- Description: "SSH from admin laptop only"

DO NOT ADD:
❌ MySQL port 3306 (even inbound from WEB server)
❌ Any traffic from SG-WEB
❌ Any traffic from SG-STORAGE
❌ Any public HTTP/HTTPS
❌ Any EC2-to-EC2 communication

3. Click "Save rules"

SCREENSHOT 3.3: Show SG-DB inbound rules with ONLY SSH rule from admin IP
Make sure no other rules are visible.

4. Click "Edit outbound rules":
   Remove all default rules if possible, or leave minimal outbound (typically 
   everything is allowed by default for outbound, but you should restrict it to:
   - DNS (53) to 0.0.0.0/0 (for domain lookups if needed)
   - No outbound to other EC2 instances

SCREENSHOT 3.4: Show SG-DB outbound rules


STEP 3.3 - CONFIGURE SG-STORAGE SECURITY GROUP
-----------
1. Find and click "SG-STORAGE"
2. Click "Edit inbound rules"

Delete any existing rules - this instance should have NO inbound traffic 
from EC2 instances:

DO NOT ADD:
❌ Any traffic from SG-WEB
❌ Any traffic from SG-DB
❌ Any EC2-to-EC2 communication
❌ Any public HTTP/HTTPS ports
❌ SSH (unless you need it for troubleshooting)

Note: API Gateway access to S3 does NOT use Security Groups - it uses IAM roles

3. For now, keep inbound empty or add only SSH from admin IP if needed

SCREENSHOT 3.5: Show SG-STORAGE inbound rules (empty or minimal)
Caption: "No EC2-to-EC2 traffic allowed"

4. Click "Edit outbound rules":
   Keep default (all outbound allowed) OR restrict to:
   - HTTPS (443) to 0.0.0.0/0 (for calling AWS services/API Gateway)
   - DNS (53) to 0.0.0.0/0

SCREENSHOT 3.6: Show SG-STORAGE outbound rules


STEP 3.4 - VERIFY ISOLATION (TESTING PHASE)
-----------
Now verify that instances CANNOT communicate with each other.

1. SSH into WEB-SERVER:
   ssh -i lab3-key.pem ubuntu@<WEB-SERVER-PUBLIC-IP>

2. Try to connect to DB-SERVER's MySQL port (should timeout/fail):
   telnet <DB-SERVER-PRIVATE-IP> 3306
   (This should hang/timeout - Press Ctrl+C)

SCREENSHOT 3.7: Show the timeout attempt to DB-SERVER

3. Try to SSH to DB-SERVER (should fail):
   ssh -i lab3-key.pem ubuntu@<DB-SERVER-PRIVATE-IP>
   (This should timeout - Press Ctrl+C)

4. Exit WEB-SERVER:
   exit

5. SSH into DB-SERVER:
   ssh -i lab3-key.pem ubuntu@<DB-SERVER-PUBLIC-IP>

6. Try to reach WEB-SERVER:
   curl http://<WEB-SERVER-PRIVATE-IP>:80
   (This should timeout/fail)

7. Exit DB-SERVER:
   exit

SCREENSHOT 3.8: Show another timeout attempt confirming EC2-to-EC2 isolation

All instances are now isolated and cannot communicate directly. ✓

================================================================================
TASK 4: CREATE S3 BUCKET AND UPLOAD FILES
================================================================================

STEP 4.1 - CREATE S3 BUCKET
-----------
1. In AWS Console, navigate to S3 → "Create bucket"
2. Configure bucket:
   Bucket name: lab3-bucket-<your-account-id> (must be globally unique)
   Region: Same as your EC2 instances (e.g., us-east-1)
   
3. Block Public Access:
   Keep all "Block public access" settings CHECKED (default)
   
4. Versioning: Disable (optional)

5. Encryption: Enable (default)

6. Click "Create bucket"

SCREENSHOT 4.1: Show the S3 bucket created with its name visible
Bucket name: ___________________________________

STEP 4.2 - CREATE IAM POLICY FOR S3 ACCESS
-----------
1. Go to IAM → Policies → "Create policy"
2. Choose JSON editor
3. Paste the following policy:

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::lab3-bucket-<YOUR-ACCOUNT-ID>",
        "arn:aws:s3:::lab3-bucket-<YOUR-ACCOUNT-ID>/*"
      ]
    }
  ]
}

Replace <YOUR-ACCOUNT-ID> with your actual AWS account ID

4. Click "Next"
5. Name the policy: "Lab3-S3-ReadOnly-Policy"
6. Description: "Allows STORAGE-SERVER to read S3 bucket objects"
7. Click "Create policy"

SCREENSHOT 4.2: Show the created policy with the JSON visible

STEP 4.3 - CREATE IAM ROLE FOR STORAGE-SERVER
-----------
1. Go to IAM → Roles → "Create role"
2. Select trusted entity type: AWS service
3. Choose use case: EC2
4. Click "Next"
5. Search for and select "Lab3-S3-ReadOnly-Policy"
6. Click "Next"
7. Role name: "Lab3-StorageServerRole"
8. Description: "Allows STORAGE-SERVER to access S3 bucket via API Gateway"
9. Click "Create role"

SCREENSHOT 4.3: Show the created role with trust relationship and policy visible

STEP 4.4 - ATTACH ROLE TO STORAGE-SERVER INSTANCE
-----------
1. Go to EC2 → Instances
2. Select "STORAGE-SERVER"
3. Click "Actions" → "Security" → "Modify IAM instance profile"
4. Select role: "Lab3-StorageServerRole"
5. Click "Update"

Wait for the operation to complete.

SCREENSHOT 4.4: Show the IAM instance profile updated on STORAGE-SERVER

STEP 4.5 - UPLOAD TEST FILES TO S3 BUCKET
-----------
1. In AWS Console, open your S3 bucket
2. Click "Upload"
3. Add files:
   - Create a simple text file locally: test.txt with content "Lab 3 Test File"
   - Upload it
   
4. Upload another file (optional): document.pdf or image.jpg

5. Make sure files are uploaded and visible in the bucket

SCREENSHOT 4.5: Show S3 bucket with uploaded files visible
List the files: __________________________

================================================================================
TASK 5: CREATE API GATEWAY TO ACCESS S3
================================================================================

STEP 5.1 - CREATE REST API
-----------
1. In AWS Console, go to API Gateway
2. Click "Create API"
3. Choose REST API (not HTTP API)
4. Select "Build"
5. Configure:
   Protocol: REST
   Create new API
   API name: "Lab3-StorageAPI"
   Description: "API Gateway for secure S3 access"
   Endpoint type: Regional
   
6. Click "Create API"

SCREENSHOT 5.1: Show the newly created API with the ID visible

STEP 5.2 - CREATE RESOURCE AND METHOD
-----------
1. In the API Gateway console, you should see the API resources
2. Click on root "/" resource
3. Click "Create method" → "GET"
4. Integration type: AWS Service
5. Configure:
   AWS Region: (same as your S3 bucket, e.g., us-east-1)
   AWS Service: S3
   HTTP method: GET
   Action Type: Use path override
   Path override: /lab3-bucket-<YOUR-ACCOUNT-ID>/{object}
   
6. Execution role ARN: Create or use an existing role that has S3 read access

7. Click "Create method"

SCREENSHOT 5.2: Show the GET method configuration with S3 integration

STEP 5.3 - CONFIGURE REQUEST MAPPING
-----------
1. In the GET method, click on "Integration request"
2. Expand "URL Path Parameters"
3. Add mapping:
   Name: object
   Mapped from: method.request.path.object

SCREENSHOT 5.3: Show the URL path parameter mapping

STEP 5.4 - DEPLOY API
-----------
1. Back in the API, click "Deploy"
2. Configure:
   Stage name: prod
   Description: "Production stage"
   
3. Click "Deploy"

SCREENSHOT 5.4: Show the deployed API with the "Invoke URL" visible
Copy and note the Invoke URL:
___________________________________________________________

STEP 5.5 - TEST API LOCALLY
-----------
1. Go to Stages → prod
2. Note the Invoke URL
3. Test the API by calling it from a browser or curl:
   curl https://<API-ID>.execute-api.<REGION>.amazonaws.com/prod/test.txt
   
   (Replace <API-ID> and <REGION> with actual values)

If configured correctly, you should get back the contents of test.txt from S3.

SCREENSHOT 5.5: Show successful API call output in terminal (curl response)

================================================================================
TASK 6: TEST API GATEWAY FROM STORAGE-SERVER
================================================================================

STEP 6.1 - SSH INTO STORAGE-SERVER
-----------
1. In terminal:
   ssh -i lab3-key.pem ubuntu@<STORAGE-SERVER-PUBLIC-IP>

SCREENSHOT 6.1: Show SSH connection to STORAGE-SERVER

STEP 6.2 - TEST API GATEWAY CALL
-----------
1. Call the API Gateway from STORAGE-SERVER:
   curl https://<API-ID>.execute-api.<REGION>.amazonaws.com/prod/test.txt
   
   (Replace with your actual API invoke URL)

2. You should receive the file contents from S3

SCREENSHOT 6.2: Show successful curl output with file contents from S3

STEP 6.3 - VERIFY ISOLATION
-----------
1. Try to access S3 directly (this should fail because we didn't allow it):
   aws s3 cp s3://lab3-bucket-<ACCOUNT-ID>/test.txt -
   
   (This might fail if the IAM role doesn't have direct S3 access,
    which is good - we want API Gateway mediation)

2. Exit STORAGE-SERVER:
   exit

SCREENSHOT 6.3: Show error message or "Access Denied" when trying direct S3 access
(This confirms API Gateway is the required path)

================================================================================
TASK 7: CLOUDWATCH MONITORING AND ALARMS
================================================================================

STEP 7.1 - CREATE CPU UTILIZATION ALARM FOR WEB-SERVER
-----------
1. In AWS Console, go to CloudWatch → Alarms → "Create alarm"
2. Configure:
   Metric: EC2 → Per-Instance Metrics → CPU Utilization
   Instance: WEB-SERVER
   Statistic: Average
   Period: 5 minutes
   
3. Set threshold:
   Condition: Greater than
   Threshold: 70
   Datapoints to alarm: 2 (consecutive periods)
   
4. In Alarm state action:
   Send notification to: Create new SNS topic
   Topic name: Lab3-CPU-Alert
   Email: Your email address
   
5. Click "Create alarm"

SCREENSHOT 7.1: Show the created alarm in CloudWatch
Alarm name: ________________________________

STEP 7.2 - CONFIRM SNS EMAIL SUBSCRIPTION
-----------
1. Check your email for a subscription confirmation from SNS
2. Click the confirmation link
3. You should receive a "Subscription confirmed" message

SCREENSHOT 7.2: Show the SNS subscription confirmation email

STEP 7.3 - GENERATE CPU LOAD ON WEB-SERVER
-----------
1. SSH into WEB-SERVER:
   ssh -i lab3-key.pem ubuntu@<WEB-SERVER-PUBLIC-IP>

2. Generate CPU load:
   sudo apt install -y stress
   stress --cpu 1 --timeout 300s &
   
   This will stress test the CPU for 5 minutes

3. Monitor the process:
   top
   (Press q to exit)

SCREENSHOT 7.3: Show CPU usage spiking above 70% in top output

4. Exit WEB-SERVER:
   exit

STEP 7.4 - MONITOR ALARM
-----------
1. In CloudWatch → Alarms
2. Watch the WEB-SERVER CPU alarm status
3. Wait 10-15 minutes for the alarm to transition to "ALARM" state
4. Check your email for the alarm notification

SCREENSHOT 7.4: Show CloudWatch alarm in "ALARM" state (red)

SCREENSHOT 7.5: Show email notification from SNS with alarm details

The alarm demonstrates that CloudWatch is properly monitoring and alerting. ✓

================================================================================
TASK 8: CLOUDTRAIL FOR SUSPICIOUS ACTIVITY LOGGING
================================================================================

STEP 8.1 - CREATE CLOUDTRAIL
-----------
1. In AWS Console, go to CloudTrail → Trails
2. Click "Create trail"
3. Configure:
   Trail name: Lab3-SecurityTrail
   S3 bucket: Create new bucket
   S3 bucket name: lab3-cloudtrail-<ACCOUNT-ID>
   Enable log file validation: Yes
   Include global service events: Yes
   
4. Click "Next"
5. Keep default event types (API calls)
6. Click "Create trail"

SCREENSHOT 8.1: Show the created CloudTrail trail
Trail name: ________________________________

STEP 8.2 - ENABLE TRAIL
-----------
1. In CloudTrail dashboard, select the trail "Lab3-SecurityTrail"
2. If not already enabled, click "Start logging"

SCREENSHOT 8.2: Show trail status as "Logging: On"

STEP 8.3 - GENERATE SUSPICIOUS ACTIVITY
-----------
Now intentionally trigger events that will be logged:

ACTIVITY 1: Attempt unauthorized S3 access
1. Create a new IAM user (or use existing):
   - Go to IAM → Users → Create user
   - Username: lab3-test-user
   - Do NOT attach S3 permissions
   
2. Generate access keys for this user:
   - Select user → Security credentials → Create access key
   - Choose "Command Line Interface"
   - Download the credentials
   
3. Configure AWS CLI with this new user's credentials:
   (In a separate terminal or profile)
   aws configure --profile lab3-test-user
   
4. Try to access S3 with limited user:
   aws s3 ls --profile lab3-test-user
   
   This will generate an "Access Denied" event in CloudTrail

SCREENSHOT 8.3: Show "Access Denied" error in terminal

SCREENSHOT 8.4: Take a screenshot showing the access key creation in IAM


ACTIVITY 2: Attempt to stop EC2 instance without permission
1. Using the lab3-test-user credentials, try:
   aws ec2 stop-instances --instance-ids i-<WEB-SERVER-ID> --profile lab3-test-user
   
   This will fail and be logged in CloudTrail

SCREENSHOT 8.5: Show "UnauthorizedOperation" error in terminal


STEP 8.4 - ANALYZE CLOUDTRAIL LOGS
-----------
1. In CloudTrail → Event History
2. You should see events like:
   - GetObject failures
   - StopInstances denials
   - Other API calls with error codes
   
3. Click on an event to view details:
   - Event source
   - Event name
   - Error code
   - User identity
   - Source IP
   - Timestamp

SCREENSHOT 8.6: Show CloudTrail Event History with multiple events visible

SCREENSHOT 8.7: Click on a "failure" event and show the details:
Details should include:
- Error code (e.g., "AccessDenied")
- Principal/User ID
- Event time
- Source IP address
- Action attempted (GetObject, StopInstances, etc.)

STEP 8.5 - VIEW LOGS IN S3
-----------
1. Go to S3 → lab3-cloudtrail-<ACCOUNT-ID> bucket
2. Logs are stored in:
   AWSLogs/ACCOUNT-ID/CloudTrail/REGION/YEAR/MONTH/DAY/
   
3. Download a log file (JSON format)

SCREENSHOT 8.8: Show S3 bucket structure with CloudTrail logs
Show the nested folder structure: AWSLogs → CloudTrail

SCREENSHOT 8.9: Download and view a CloudTrail JSON log file
Show the file contents highlighting:
- userIdentity (who performed the action)
- sourceIPAddress
- eventName (action attempted)
- errorCode (e.g., "AccessDenied")
- eventTime (timestamp)

================================================================================
TASK 9: DOCUMENT AND PREPARE FOR SUBMISSION
================================================================================

STEP 9.1 - COMPILE SECURITY GROUP SCREENSHOTS
-----------
Document all security group configurations:
□ SG-WEB inbound rules (HTTPS only)
□ SG-WEB outbound rules
□ SG-DB inbound rules (SSH only from admin)
□ SG-DB outbound rules
□ SG-STORAGE inbound rules (empty)
□ SG-STORAGE outbound rules

Create a document with these screenshots clearly labeled.

STEP 9.2 - PREPARE IAM POLICY DOCUMENTS
-----------
Export the following as JSON files:
□ Lab3-S3-ReadOnly-Policy (policy attached to STORAGE-SERVER)
□ Lab3-StorageServerRole (trust relationship)
□ Trust policy document

Save them as:
- lab3-s3-policy.json
- lab3-storage-role-trust.json

STEP 9.3 - DOCUMENT API GATEWAY
-----------
Prepare:
□ API Gateway Invoke URL: _____________________________
□ Method configuration (GET method details)
□ Screenshot of successful curl call from STORAGE-SERVER
□ Screenshot of successful API response

STEP 9.4 - DOCUMENT CLOUDWATCH
-----------
Collect:
□ CloudWatch alarm configuration screenshot
□ Alarm state "ALARM" screenshot
□ SNS email notification screenshot
□ top output showing CPU spike

Create a document labeled "CloudWatch-Monitoring.md" with these items.

STEP 9.5 - DOCUMENT CLOUDTRAIL
-----------
Collect:
□ CloudTrail trail creation screenshot
□ Event History showing multiple events
□ Detailed view of at least 2 suspicious events:
  * Error code visible
  * User identity visible
  * Timestamp visible
  * Source IP visible
□ CloudTrail log file (JSON snippet from S3)

Create a document labeled "CloudTrail-Logs.md"

STEP 9.6 - PREPARE TEST RESULTS
-----------
Document:
□ Screenshot of WEB-SERVER Nginx page (via browser with public IP)
□ Screenshot of DB-SERVER MySQL connection and test table
□ Screenshot of STORAGE-SERVER S3 API Gateway call (curl output)
□ Screenshot of instance isolation tests (connection timeouts)

STEP 9.7 - WRITE REFLECTION ANSWERS
-----------
Answer the following questions in detail (500+ words total):

1. Why is IAM required when the Storage Instance uses S3?
   Explain how IAM provides temporary credentials, role-based access,
   least privilege principle, and auditability.
   
2. Why must EC2 instances be isolated using security groups?
   Explain defense-in-depth, blast radius reduction, and compliance requirements.
   
3. What would be the risk if SG-WEB allowed port 3306 (MySQL) inbound?
   Explain direct compromise, data exfiltration, and compliance violations.
   
4. How does CloudTrail help detect attack attempts?
   Explain audit logging, forensic analysis, and real-time alerting.
   
5. Compare direct S3 access vs API Gateway-mediated access.
   Explain control flow, auditability, and versioning capabilities.
   
6. What challenges did you face implementing instance isolation?
   Discuss troubleshooting, testing methodology, and lessons learned.
   
7. What would change if we enabled VPC Endpoints for S3?
   Explain private connectivity, data exfiltration prevention, and cost savings.

STEP 9.8 - PREPARE FINAL ZIP PACKAGE
-----------
Create a folder: "Lab3-Submission"

Inside, organize:
├── Lab3-Submission/
│   ├── report.pdf (Your LaTeX lab report)
│   ├── screenshots/
│   │   ├── 01-instances/
│   │   ├── 02-security-groups/
│   │   ├── 03-iam-roles/
│   │   ├── 04-api-gateway/
│   │   ├── 05-cloudwatch/
│   │   ├── 06-cloudtrail/
│   │   └── 07-testing/
│   ├── code/
│   │   ├── lab3-s3-policy.json
│   │   ├── lab3-storage-role-trust.json
│   │   ├── cloudtrail-sample-log.json
│   │   └── api-gateway-config.json
│   ├── reflection/
│   │   └── reflection-answers.txt
│   └── api-invoke-url.txt

STEP 9.9 - VERIFY ALL REQUIREMENTS
-----------
Before submission, verify:

□ 7+ Security Group rule screenshots (SG-WEB, SG-DB, SG-STORAGE)
□ 2+ IAM policy files (JSON format)
□ API Gateway invoke URL documented
□ API Gateway call screenshot (curl response)
□ CloudWatch alarm configuration screenshot
□ CloudWatch alarm triggered (ALARM state) screenshot
□ SNS email notification screenshot
□ 2+ CloudTrail suspicious event logs with details
□ S3 bucket screenshot with uploaded files
□ WEB-SERVER Nginx page screenshot
□ DB-SERVER MySQL test screenshot
□ API Gateway S3 response screenshot
□ Instance isolation test screenshots (showing timeouts)
□ 7 reflection questions answered thoroughly
□ Contribution section with team member names and roles

STEP 9.10 - CREATE VIDEO DEMONSTRATION
-----------
Record a 5-10 minute video showing:

1. AWS Console overview:
   - Show all 3 EC2 instances running
   - Show 3 security groups and their rules
   
2. Web application:
   - Access WEB-SERVER via HTTPS (browser screenshot)
   - Show Nginx page
   
3. Database:
   - SSH to DB-SERVER
   - Show MySQL is running
   - Show test table
   
4. API Gateway:
   - Show API Gateway configuration
   - Call API from STORAGE-SERVER using curl
   - Show response with S3 file contents
   
5. Instance isolation:
   - Attempt SSH between instances (show timeout)
   - Attempt MySQL connection (show timeout)
   
6. CloudWatch:
   - Show alarm configuration
   - Show alarm triggered
   
7. CloudTrail:
   - Show Event History
   - Show suspicious event details
   
8. Reflection:
   - Briefly discuss key learnings and security benefits

Upload video to Canvas or provide link.

================================================================================
SUMMARY OF KEY POINTS FOR IMPLEMENTATION
================================================================================

SECURITY PRINCIPLES DEMONSTRATED:
✓ Defense in Depth: Multiple layers (SG, IAM, API Gateway, S3)
✓ Least Privilege: Instances only have minimal required permissions
✓ Zero Trust: No EC2-to-EC2 communication allowed
✓ Auditability: CloudTrail logs all API calls
✓ Monitoring: CloudWatch provides real-time alerts

ARCHITECTURE ACHIEVED:
✓ Web Server: Isolated, accessible only via HTTPS from public internet
✓ Database: Isolated, accessible only via SSH from admin IP
✓ Storage: Isolated, accessible only via API Gateway, not direct EC2 connection
✓ S3 Bucket: Protected by IAM roles, accessed through API Gateway
✓ API Gateway: Single point of control for storage access
✓ CloudWatch: Monitors CPU and other metrics, triggers alarms
✓ CloudTrail: Logs all API calls and failed attempts

ISOLATION VERIFICATION:
✓ EC2-to-EC2 traffic: BLOCKED by security groups
✓ Direct database access: BLOCKED by security group rules
✓ Direct S3 access: BLOCKED by lack of API Gateway integration
✓ Public SSH: BLOCKED except from admin IP to DB only
✓ Web server database connectivity: BLOCKED by network rules

================================================================================
IMPORTANT NOTES
================================================================================

1. ALWAYS use your admin IP address for SSH access to DB-SERVER
2. NEVER publicly expose MySQL or any databases
3. Keep your lab3-key.pem file secure - do not share
4. Test security groups thoroughly before moving to next step
5. CloudWatch alarms take 10-15 minutes to transition between states
6. CloudTrail logs take 5-10 minutes to appear in S3
7. Make sure to clean up (delete) CloudTrail trail and S3 buckets after lab
   to avoid unnecessary AWS charges
8. Document each step with screenshots - these are REQUIRED for grading
9. Include all team member contributions clearly
10. Submit as ZIP file with all screenshots and code files

================================================================================
DEADLINE: December 10, 2025
Submit PDF report, screenshots, code files, and video to Canvas
================================================================================
